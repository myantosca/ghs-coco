\documentclass[11pt,epsf]{article}
\usepackage{amssymb,amsmath,amsthm,amsfonts,mathrsfs,color}
\usepackage{epsfig}
\usepackage{latexsym}
\usepackage{verbatim}
\usepackage{setspace}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{algorithmicext}
\usepackage{ifthen}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}
\usepackage[utf8]{luainputenc}
\usepackage[bibencoding=utf8,backend=biber]{biblatex}
\addbibresource{cosc6326-final-michael-yantosca.bib}
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{{\footnotesize{COSC6326 Final Project}}}
\rhead{{\footnotesize{Michael Yantosca}}}

\usepackage{longtable}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepgfplotslibrary{external}
\usepgfplotslibrary{statistics}
\usepgfplotslibrary{groupplots}
\usetikzlibrary{pgfplots.groupplots, external}
\tikzexternalize[]
\pgfplotsset{
  tick label style={font=\footnotesize},
  label style={font=\small},
  legend style={font=\small},
  compat=newest
}
\pgfplotstableset{
  col sep=comma,
  begin table=\begin{longtable},
  end table=\end{longtable},
  every head row/.append style={after row=\endhead}
}

\newtheorem{fact}{Fact}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{example}{Example}
\newtheorem{observation}{Observation}
\newtheorem{exercise}{Exercise}
\newtheorem{statement}{Statement}
\newtheorem{problem}{Problem}

\newcommand{\TODO}[0]{\textbf{\color{red}{TODO}}}

% \linregplots{title}{prefix}{suffix}{x}{y}
\newcommand{\linregplots}[5]{
  \nextgroupplot[title=#1]
  \addplot [red, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k1#3.csv};
  \addplot [red, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k1#3.csv};
  \addplot [blue, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k2#3.csv};
  \addplot [blue, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k2#3.csv};
  \addplot [green, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k4#3.csv};
  \addplot [green, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k4#3.csv};
  \addplot [orange, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k8#3.csv};
  \addplot [orange, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k8#3.csv};
  \addplot [purple, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k16#3.csv};
  \addplot [purple, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k16#3.csv};
  \addplot [brown, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k32#3.csv};
  \addplot [brown, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k32#3.csv};
}

\date{}
\title{COSC6326 Programming Assignment 2}
\author{Michael Yantosca}
\begin{document}
\maketitle
\tableofcontents

\section{Introduction}{
  \paragraph{}{
    The study of graph connectivity can yield insight into problem spaces in communication
    efficiency. Knowing where links are in a given graph can inform routing and help determine
    the best information dissemination strategies. Starting from a clean-room environment with
    graphs whose edges are a function of randomness, universal properties about
    graph connectivity may be uncovered that can then be applied to real-world examples
    to further refine the theory. Previously, experiments were conducted that tested the efficacy
    of a BFS algorithm in determining connected components, and a novel but incomplete method
    of randomized graph generation was used to speed up the generation process\autocite{bfs-coco}. In this set of experiments,
    the discovery of connected components through the use of the Gallager-Humblet-Spira (GHS) algorithm\autocite[102-106]{DNA}
    is explored on the same set of Erdos-Renyi graphs\autocite[5]{pa2spec} and real world datasets from the
    SNAP database\autocite{SNAP} for experimental consistency.
  }
}

\section{Analysis}{
  \subsection{\texttt{ghs-coco}}{
    \paragraph{}{
      The GHS algorithm for finding connected components is given below in Algorithm~\ref{alg:ghs-coco}.
      For the sake of legibility, several helper functions and procedures are abstracted out
      from the main body and presented following the main algorithm. In the implementation,
      only Algorithm~\ref{alg:exchange-all} and Algorithm~\ref{alg:exchange-one} are actually abstracted out into separate functions.
      All other sub-algorithms run within the main context to avoid unnecessary function call overhead,
      particularly Algorithm~\ref{alg:machine-hash}.
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{GHS-Connected-Components}, GHS Algorithm Modified to Determine Connected Components in an Arbitrary Graph}
        \label{alg:ghs-coco}
        \begin{algorithmic}
          \REQUIRE{$k$, the process/machine rank}
          \REQUIRE{$F$, the binary-format, edge-centric graph model input file}
          \IF{$r = 0$}{
            \STATE{Sample $h_a$ from an independent uniform distribution $U_a$ over $[1,M_{61} - 1]$.}
            \STATE{Sample $h_b$ from an independent uniform distribution $U_b$ over $[0,M_{61} - 1]$.}
          }\ENDIF
          \STATE{Distribute $h_a$ and $h_b$ to all machines.}
          \STATE{$(V_r, E_r) \gets \textsc{Load-Edge-To-Vertex-Centric}(F, k)$}

          \STATE{Initialize exchange info $X_{S}$.}
          \STATE{$T_r \gets \emptyset$}
          \COMMENT{local component set}

          \STATE{$w_r \gets |V_r|$}
          \FORALL{$v \in V_r$}{
            \IF{$M(v) = \emptyset$ and $N(v) = \emptyset$}{
              \STATE{$T_0 \gets T_0 \cup \{ v \}$}
            }\ELSE{
              \STATE{$T_r \gets T_r \cup \{ v \}$}
            }\ENDIF
          }\ENDFOR

          \STATE{$\omega_r \gets |T_r| = 0$}
          \COMMENT{local termination = no nodes with outgoing edges}
          \STATE{$\Omega \gets \land_{r=1}^{k} \omega_r$}
          \COMMENT{global termination = no nodes with outgoing edges anywhere}
          \WHILE{$\neg \Omega$}{
            \FORALL{$t \in T_r$}{
              \STATE{$s(t) \gets \textsc{FindTest}$}
              \COMMENT{Initialize component roots to find MWOE.}
              \STATE{$u_e(t) \gets i(t)$}
              \STATE{$v_e(t) \gets i(t)$}
              \COMMENT{Reset MWOE to self-reference.}
              \STATE{$S_r \gets \{ t \}$}
              \COMMENT{Add each node to the find phase work queue.}
            }\ENDFOR
            \STATE{Execute \textsc{GHS-Connected-Components-Find-MWOE} phase.}
            \STATE{$n_j \gets 0$}
            \COMMENT{Initialize join count.}
            \STATE{Execute \textsc{GHS-Connected-Components-Merge} phase.}
            \STATE{$\omega_r \gets n_j = 0$}
            \COMMENT{Local termination = no joins.}
            \STATE{$\Omega \gets \land_{r=1}^{k} \omega_r$}
            \COMMENT{Global termination = no joins anywhere.}
          }\ENDWHILE
          \STATE{Execute \textsc{Component-Census} phase.}
        \end{algorithmic}
      \end{algorithm}
    }

    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Exchange-All}, Machine-wise Exchange of Information}
        \label{alg:exchange-all}
        \begin{algorithmic}
          \REQUIRE{$X_i$, exchange information for machine $i$}
          \REQUIRE{$send(X_i)[m]$, send buffer targeting machine $m$ from machine $i$}
          \REQUIRE{$recv(X_m)$, receive buffer for machine $m$}
          \REQUIRE{$k$, the number of machines participating}
          \FOR{$m \in [0,k-1]$}{
            \STATE{\textsc{Exchange-One}($X_i$)}
          }\ENDFOR
        \end{algorithmic}
      \end{algorithm}
    }

    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Exchange-One}, Gathering of Information at One Machine}
        \label{alg:exchange-one}
        \begin{algorithmic}
          \REQUIRE{$X_i$, exchange information for machine $i$}
          \REQUIRE{$send(X_i)[m]$, send buffer targeting machine $m$ from machine $i$}
          \REQUIRE{$recv(X_m)$, receive buffer for machine $m$}
          \REQUIRE{$k$, the number of machines participating}
          \STATE{Machine $m$ gathers $len(send(X_i)[m])$ from all machines.}
          \STATE{Machine $m$ allocates $\sum_{i=0}^{k-1} len(send(X_i)[m])$ for $recv(X_m)$.}
          \STATE{$recv(X_m) \gets concat(\{ send(X_i)[m] \ | \  0 \leq i < k \})$}
        \end{algorithmic}
      \end{algorithm}
      Algorithm~\ref{alg:exchange-one} is abstracted out from the inside of the loop
      in Algorithm~\ref{alg:exchange-all} for the purpose of enabling a simple gather
      of the component statistics upon the termination of Algorithm~\ref{alg:ghs-coco}.
    }


    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Machine-Hash}, Universal Hashing Function for Mapping Vertices to Machines}
        \label{alg:machine-hash}
        \begin{algorithmic}
          \REQUIRE{$M_{61}$, the Mersenne prime $2^{61} - 1$}
          \REQUIRE{$h_a$, an integer in the range $[1,M_{61} - 1]$}
          \REQUIRE{$h_b$, an integer in the range $[0,M_{61} - 1]$}
          \REQUIRE{$k$, the number of machines}
          \REQUIRE{$i_v$, the vertex id to be hashed to some machine $m_h$}
          \RETURN{$((h_ai_v + h_b) \mod M_{61}) \mod k$}
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Load-Edge-To-Vertex-Centric}, Distributed Algorithm for Loading an Edge-Centric Storage Model and Converting to a Vertex-Centric Memory Model}
        \label{alg:le2v}
        \begin{algorithmic}
          \REQUIRE{$F$, the binary-format, edge-centric graph model input file}
          \STATE{Initialize edge exchange info $X_e$.}
          \STATE{Open $F$ for reading.}
          \STATE{$S_F \gets $ the input file size}
          \STATE{$|E| \gets S_F / 8$}
          \STATE{$|E|_{\bar{k}} \gets S_F / k$}
          \STATE{$|E|_r \gets S_F \mod k$}
          \IF{$r < |E|_r$}{
            \STATE{$|E|_k \gets |E|_{\bar{k}} + 1$}
          }
          \ELSE{
            \STATE{$|E|_k \gets |E|_{\bar{k}}$}
          }\ENDIF
          \STATE{Read $|E|_k$ bytes with offset proportional to $k$ into $E_r$.}
          \STATE{Close $F$.}
          \FOR{$i \in [0, |E|_k-1]$}{
            \STATE{$e_{uv} \gets (E_r[2i],E_r[2i+1])$}
            \STATE{$e_{vu} \gets (E_r[2i+1],E_r[2i])$}
            \STATE{$m_u \gets \textsc{Machine-Hash}(h_a, h_b, k, e_{uv}[0])$}
            \STATE{$m_v \gets \textsc{Machine-Hash}(h_a, h_b, k, e_{vu}[0])$}
            \STATE{Add $e_{uv}$ to the exchange buffer for $m_u$.}
            \STATE{Add $e_{vu}$ to the exchange buffer for $m_v$.}
          }\ENDFOR
          \STATE{\textsc{Exchange-All}($X_e$)}
          \STATE{$E_r \gets \emptyset$}
          \FOR{$(i_u,i_v) \in E_{rcvd}$}{
            \STATE{$u \gets V_r[i_u]$}
            \IF{$u = \bot$}{
              \STATE{$u \gets \{ i = i_p = i_g = u_e = v_e = i_u, |g| = 1, s = \bot, w = 0, N = \emptyset, C = \emptyset, M = \emptyset \}$}
              \STATE{$V_r[i_u] \gets u$}
            }\ENDIF
            \IF{$i_u \neq i_v$}{
              \STATE{$N(u) \gets N(u) \cup \{ i_v \}$}
              \IF{$i_v \notin E_r$}{
                \STATE{$E_r[i_v] \gets \emptyset$}
              }\ENDIF
              \STATE{$E_r[i_v] \gets E_r[i_v] \cup \{ i_u \}$}
            }\ENDIF
          }\ENDFOR
          \RETURN{$(V_r, E_r)$}
        \end{algorithmic}
      \end{algorithm}
    }

    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{GHS-Connected-Components-Find-MWOE}, Link Phase of Algorithm~\ref{alg:ghs-coco} }
        \label{alg:ghs-coco-find-mwoe}
        \begin{algorithmic}
          \REQUIRE{$T_0$, the set of local component roots where $|M \cup N| = 0$}
          \REQUIRE{$T_r$, the set of local component roots where $|M \cup N| > 0$}
          \REQUIRE{$V_r$, the full set of local nodes}
          \REQUIRE{$E_r$, the reverse lookup table of incoming edges}
          \REQUIRE{$S_r \gets \emptyset$, the set of nodes sending messages}
          \REQUIRE{$V_e \gets \emptyset$, the set of nodes holding minimum edges}
          \REQUIRE{$w_L \gets |V_r| - |T_0|$, the number of components with at least one incident edge}
          \STATE{$\omega_e \gets w_L = 0$}
          \STATE{$\Omega_e \gets \land_{r=1}^{k} \omega_e$}
          \WHILE{$\neg \Omega_e$}{
            \STATE{Execute \textsc{GHS-Connected-Components-Find-MWOE-Send} phase.}
            \STATE{Execute \textsc{GHS-Connected-Components-Find-MWOE-Receive} phase.}
            \STATE{$\omega_e \gets w_L = 0$}
            \STATE{$\Omega_e \gets \land_{r=1}^{k} \omega_e$}
          }\ENDWHILE
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{GHS-Connected-Components-Find-MWOE-Send}, Send Phase of Algorithm~\ref{alg:ghs-coco-find-mwoe} }
        \label{alg:ghs-coco-find-mwoe-send}
        \begin{algorithmic}
          \WHILE{$S_r \neq \emptyset$}{
            \STATE{$u \gets \textsc{Pop}(S_r)$}
            \IF{$s(u) = \textsc{FindTest}$}{
              \IF{$N(u) > 0$}{
                \STATE{$i_v \gets \min\limits_{v \in N(u)} v$}
                \STATE{$m_v \gets \textsc{Machine-Hash}(h_a, h_b, k, i_v)$}
                \STATE{$send(X_S)[m_v] \gets send(X_S)[m_v] + ( \textsc{ping}, i_v, i(u), i_g(u) )$}
                \COMMENT{Test vertex $i_v$.}
              }\ELSE{
                \STATE{$s(u) \gets \textsc{FindSend}$}
                \STATE{$S_r \gets S_r \cup \{ u \}$}
                \COMMENT{$\epsilon$-transition: no neighbors outside component}
              }\ENDIF
            }\ELSIF{$s(u) = \textsc{FindSend}$}{
              \STATE{$w(u) \gets |C(u)|$}
              \IF{$w(u) > 0$}{
                \STATE{$s(u) \gets \textsc{FindWait}$}
                \FORALL{$i_v \in C(u)$}{
                  \STATE{$m_v \gets \textsc{Machine-Hash}(h_a, h_b, k, i_v)$}
                  \STATE{$send(X_S)[m_v] \gets send(X_S)[m_v] + ( \textsc{find}, i_v, i(u), i_g(u) )$}
                  \COMMENT{Downcast \textsc{find}.}
                }\ENDFOR
              }\ELSE{
                \STATE{$s(u) \gets \textsc{FindReply}$}
                \STATE{$S_r \gets S_r \cup \{ u \}$}
                \COMMENT{$\epsilon$-transition: no children}
              }\ENDIF
            }\ELSIF{$s(u) = \textsc{FindReply}$}{
              \IF{$i_g(u) = i(u)$}{
                \STATE{$s(u) \gets \textsc{MwoeSend}$}
                \STATE{$S_r \gets S_r \cup \{ u \}$}
                \COMMENT{$\epsilon$-transition: component root}
              }\ELSE{
                \STATE{$s(u) \gets \textsc{Idle}$}
                \STATE{$m_p \gets \textsc{Machine-Hash}(h_a, h_b, k, i_p(u))$}
                \STATE{$send(X_S)[m_p] \gets send(X_S)[m_p] + ( \textsc{found}, i_p(u), u_e(u), v_e(u) )$}
                \COMMENT{Upcast \textsc{found}.}
              }\ENDIF
            }\ELSIF{$s(u) = \textsc{mwoe}$}{
              \STATE{$s(u) \gets \textsc{Idle}$}
              \STATE{$w_L \gets w_L - 1$}
              \FORALL{$i_v \in C(u)$}{
                \STATE{$m_v \gets \textsc{Machine-Hash}(h_a, h_b, k, i_v)$}
                \STATE{$send(X_S)[m_v] \gets send(X_S)[m_v] + ( \textsc{mwoe}, i_v, u_e(u), v_e(u) )$}
                \COMMENT{Downcast \textsc{mwoe}.}
              }\ENDFOR
            }\ENDIF
          }\ENDWHILE

          \STATE{$\textsc{Exchange-All}(X_S)$}
          \STATE{$\textsc{Rewind}(X_S)$}
        \end{algorithmic}
      \end{algorithm}
      Algorithm~\ref{alg:ghs-coco-find-mwoe-send} is a straightforward breakdown based on \emph{vertex state}.
    }
    \paragraph{$s(u) = \textsc{FindTest}$}{
      If the vertex $u$ has neighbors in its active set, it sends a \textsc{ping} message along
      its minimum outgoing edge (here defined as the minimum opposite node label). It expects a
      \textsc{pong} message from the opposite node indicating the other's group label.
      If $u$ has no active neighbors, i.e., neighbors that are \emph{not} in its current component,
      it makes an immediate $\epsilon$-transition into the \textsc{FindSend} state.
    }
    \paragraph{$s(u) = \textsc{FindSend}$}{
      If the vertex $u$ has children, it sends a \textsc{find} message to them. It expects all children
      to reply with the minimum edge along their respective subtrees via the \textsc{found} message.
      If there are no children, the vertex makes an immediate $\epsilon$-transition into the
      \textsc{FindReply} state.
    }
    \paragraph{$s(u) = \textsc{FindReply}$}{
      If the vertex $u$ is not a component root, it sends a \textsc{found} message to its parent.
      If $u$ is a component root, it makes an immediate $\epsilon$-transition into the \textsc{MwoeSend}
      state.
    }
    \paragraph{$s(u) = \textsc{MwoeSend}$}{
      The vertex sends a \textsc{mwoe} message to all its component subchildren. It expects no response
      since termination is determined by a counter decremented on the receiving end.
    }
    \paragraph{Other States}{
      The \textsc{Idle} and \textsc{FindWait} states do not actively send messages but rather wait
      for messages to be sent to them. They are in a reactive state whose behavior is handled in
      Algorithm~\ref{alg:ghs-coco-find-mwoe-recv}.
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{GHS-Connected-Components-Find-MWOE-Receive}, Receive Phase of Algorithm~\ref{alg:ghs-coco-find-mwoe} }
        \label{alg:ghs-coco-find-mwoe-recv}
        \begin{algorithmic}
            \FORALL{$(q, i_v, a, b) \in recv(X_S)$}{
              \STATE{$v \gets V_r[i_v]$}
              \IF{$q = \textsc{ping}$}{
                \STATE{$m_u \gets \textsc{Machine-Hash}(h_a, h_b, k, a)$}
                \STATE{$send(X_S)[r] \gets send(X_S)[r] + ( \textsc{pong}, a, i_v, i_g(v) )$}
                \COMMENT{Direct buffer dump.}
              }\ELSIF{$q = \textsc{pong}$}{
                \IF{$i_g(v) = b$}{
                  \STATE{$M(v) \gets M(v) \cup \{ a \}$}
                  \STATE{$N(v) \gets N(v) \setminus \{ a \}$}
                  \COMMENT{Keep testing.}
                }\ELSE{
                  \STATE{$e_u(v) \gets i(v)$}
                  \STATE{$e_v(v) \gets a$}
                  \STATE{$s(v) \gets \textsc{FindSend}$}
                  \COMMENT{Found minimum incident edge.}
                }\ENDIF
                \STATE{$S_r \gets S_r \cup \{ v \}$}
              }\ELSIF{$q = \textsc{find}$}{
                \STATE{$s(v) \gets \textsc{FindTest}$}
                \STATE{$S_r \gets S_r \cup \{ v \}$}
              }\ELSIF{$q = \textsc{found}$}{
                \STATE{$w(v) \gets w(v) - 1$}
                \IF{$a \neq b$}{
                  \IF{$e_u(v) \neq e_v(v)$}{
                    \STATE{$e_{ab} \gets (\min(a,b), \max(a,b))$}
                    \STATE{$e_{v} \gets (\min(e_u(v), e_v(v)), \max(e_u(v), e_v(v)))$}
                    \IF{$e_{ab}[0] < e_{v}[0]$ or ($e_{ab}[0] == e_{v}[0]$ and $e_{ab}[1] < e_{v}[1]$)}{
                      \STATE{$e_u(v) \gets a$}
                      \STATE{$e_v(v) \gets b$}
                      \COMMENT{Choose the edge with the smallest endpoints.}
                    }\ENDIF
                  }\ELSE{
                    \STATE{$e_u(v) \gets a$}
                    \STATE{$e_v(v) \gets b$}
                    \COMMENT{Real edges take precedence over virtual edges.}
                  }\ENDIF
                }\ENDIF
                \IF{$w(v) = 0$}{
                  \STATE{$s(v) \gets \textsc{FindReply}$}
                  \STATE{$S_r \gets S_r \cup \{ v \}$}
                  \COMMENT{All children have responded. Transition to next state.}
                }\ENDIF
              }\ELSIF{$q = \textsc{mwoe}$}{
                \IF{$i(v) = a$} {
                  \IF{$i(v) \neq i_g(v)$}{
                    \STATE{$T_r \gets T_r \cup \{ v \}$}
                    \STATE{$T_r \gets T_r \setminus V_r[i_g(v)]$}
                    \COMMENT{Re-root fragment to vertex with MWOE.}
                  }\ENDIF
                }\ENDIF
                \STATE{$(u_e(v), v_e(v)) \gets (a,b)$}
                \STATE{$s(v) = \textsc{MwoeSend}$}
                \STATE{$S_r \gets S_r \cup \{ v \}$}
              }\ENDIF
            }\ENDFOR
        \end{algorithmic}
      \end{algorithm}
      Algorithm~\ref{alg:ghs-coco-find-mwoe-recv} is a straightforward breakdown based on \emph{message type}.
    }
    \paragraph{$q = \textsc{ping}$}{
      The vertex receives a \textsc{ping} message. Regardless of state, it needs to reply.
      The send buffer has a message added with the recipient's group label. There is no need to
      wait for the sending phase since we don't want to incur the overhead and complexity of
      quasi-states or interfere with other state transitions.
    }
    \paragraph{$q = \textsc{pong}$}{
      The pinger receives a reply. If the group labels are the same, the pinger must continue
      to ping and is added back into the sender queue. The edge is moved to the inactive set $M$
      so the next highest edge in $N$ can be chosen in the next sending phase. If the group
      labels are different, the vertex transitions into the \textsc{FindSend} state and is added to
      the sender queue. It will notify its children in the next sending phase.
    }
    \paragraph{$q = \textsc{find}$}{
      Receiving this message indicates that it is the recipient's turn to find an incident minimum
      weight edge. The vertex transitions into the \textsc{FindTest} state and is added to the sender queue.
      From this point forward, it acts as the root of its component subtree.
    }
    \paragraph{$q = \textsc{found}$}{
      Receiving this message indicates that a child subtree has propagated its minimum edge to the subtree
      root. The waiting counter is decremented. A comparsion is made to determine whether to accept the
      reported minimum edge or keep the minimum edge found by the vertex's own testing. Ordinality is
      determined by comparing the minimum node labels in each edge. Ties are broken by comparison of the
      maximum node labels in each edge. The edges themselves, however, are stored with respect to direction
      radiating from the component, i.e., the first label belongs to the component, the second outside.
      Once the counter hits zero (0), the vertex transitions to the \textsc{FindReply} state and is added
      to the sender queue to upcast its own minimum determination to its parent.
    }
    \paragraph{$q = \textsc{mwoe}$}{
      Receiving this message indicates that the root has chosen a MWOE to downcast through the tree.
      The vertex accepts this MWOE and passes it on to its own subtree. It is added to the sender queue
      for propagating the MWOE to its children. If the MWOE is incident to it, it adds itself to the
      merging set $T_r$ to participate in the merging phase and removes the component root from the set
      of roots unless the vertex is already the component root itself.
    }

    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{GHS-Connected-Components-Merge}, Merge Phase of Algorithm~\ref{alg:ghs-coco} }
        \label{alg:ghs-coco-merge}
        \begin{algorithmic}
          \FORALL{$u \in T_r$}{
            \IF{$|N(u)| > 0$}{
              \STATE{$m_v \gets \textsc{Machine-Hash}(h_a, h_b, k,v_e(u))$}
              \STATE{$send(X_S)[m_v] \gets send(X_S)[m_v] + ( \textsc{join}, v_e(u), i(u), i_g(u) )$}
              \STATE{$n_j \gets n_j + 1$}
              \COMMENT{Increment join counter to avoid premature termination.}
            }\ENDIF
          }\ENDFOR
          \STATE{$\textsc{Exchange-All}(X_S)$}
          \STATE{$\textsc{Rewind}(X_S)$}
          \STATE{$S_r \gets \emptyset$}

          \FORALL{$(\textsc{join}, i_v, i_u, i_{g(u)}) \in recv(X_S)$}{
            \STATE{$v \gets V_r[i_v]$}
            \IF{$i_u = v_e(u)$}{
              \IF{$i_v < i_u$}{
                \IF{$i_p(v) \neq i_v$}{
                  \STATE{$C(v) \gets C(v) \cup \{ i_p(v) \}$}
                }\ENDIF
                \STATE{$i_p(v) \gets v$}
                \STATE{$i_g(v) \gets v$}
                \STATE{$(e_u(v), e_v(v)) \gets v$}
                \STATE{$C(v) \gets C(v) \cup \{ i_u \}$}
                \STATE{$S_r \gets S_r \cup \{ v \}$}
                \COMMENT{Combined root goes to the minimum vertex in a mutual join.}
              }\ENDIF
            }\ELSE{
              \STATE{$C(v) \gets C(v) \cup \{ i_u \}$}
              \COMMENT{Receiving a join means adopting the sender.}
            }\ENDIF
            \STATE{$M(v) \gets M(v) \cup \{ i_u \}$}
            \STATE{$N(v) \gets N(v) \setminus \{ i_u \}$}
            \COMMENT{Prune joined edge.}
          }\ENDFOR

          \STATE{$\omega_M \gets S_r = \emptyset$}
          \STATE{$\Omega_M \gets \land_{r=1}^{k} \omega_M$}
          \WHILE{$\neg \Omega_M$}{
            \FORALL{$u \in S_r$}{
              \FORALL{$i_v \in C(u)$}{
                \STATE{$m_v \gets \textsc{Machine-Hash}(h_a, h_b, k, i_v)$}
                \STATE{$send(X_S)[m_v] \gets send(X_S)[m_v] + ( \textsc{new}, i_v, i(u), i_g(u) )$}
              }\ENDFOR
            }\ENDFOR

            \STATE{$\textsc{Exchange-All}(X_S)$}
            \STATE{$\textsc{Rewind}(X_S)$}
            \STATE{$S_r \gets \emptyset$}

            \FORALL{$(\textsc{new}, i_v, i_u, g_u) \in recv(X_S)$}{
              \STATE{$v \gets V_r[i_v]$}
              \STATE{$i_g(v) \gets g_u$}
              \COMMENT{Regroup.}
              \IF{$i_p(v) \neq i(v)$ and $i_p(v) \neq i_u$}{
                \STATE{$C(v) \gets C(v) \cup \{ i_p(v) \}$}
                \COMMENT{Adopt old parent.}
              }\ENDIF
              \STATE{$i_p(v) \gets i_u$}
              \STATE{$C(v) \gets C(v) \setminus i_u$}
              \COMMENT{Reparent.}
              \STATE{$M(v) \gets M(v) \cup \{ i_u \}$}
              \STATE{$N(v) \gets N(v) \setminus \{ i_u \}$}
              \COMMENT{Prune new parent edge.}
              \STATE{$(e_u(v), e_v(v)) \gets v$}
              \COMMENT{Reset MWOE.}
              \STATE{$T_r \gets T_r \setminus \{ v \}$}
              \COMMENT{Remove non-root from component roots.}
              \STATE{$S_r \gets S_r \cup \{ v \}$}
              \COMMENT{Add to sender queue.}
            }\ENDFOR
            \STATE{$\omega_M \gets S_r = \emptyset$}
            \COMMENT{Local termination = no more \textsc{new} messages on this machine.}
            \STATE{$\Omega_M \gets \land_{r=1}^{k} \omega_M$}
            \COMMENT{Global termination = no more \textsc{new} messages anywhere.}
          }\ENDWHILE
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      The merge phase in Algorithm ~\ref{alg:ghs-coco-merge} consists of a few simple graph-wide operations. The local component
      roots are checked for the presence of outgoing edges, and those which need to perform a join add a message to be sent
      during a $k$-way exchange among all the machines. Those that receive the messages become the targets of the join operation
      and adopt their respective senders. In the case where two vertices issue a mutual join, i.e., each sends a join request
      to the other, the vertex with the lesser vertex id becomes the parent and remains a component root. All other
      participants in the joins whether sender or receiver lose their root status so as to accomplish the necessary
      reduction dictated by the GHS algorithm. As argued in the text, at most one pair of nodes in a component-to-be
      will issue that mutual join\autocite[105]{DNA}, and one of them must be the new component root. The remainder
      of the merge phase is a simple propagation of the component root elect to its enlarged family. The root
      takes parentage of any old parent which was not itself along with its old children, if it had any. Its
      descendants are then reckoned through their prior children and in some cases parents, where a \textsc{new} message
      has caused a reparenting downstream, as well as through the join edges that brought the formerly disjoint fragments together.
    }

    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Component-Census}, Final Phase of Algorithm~\ref{alg:ghs-coco} }
        \label{alg:component-census}
        \begin{algorithmic}
          \FORALL{$u \in T_r$}{
            \STATE{$w(u) \gets |C(u)|$}
            \STATE{$S_r \gets S_r \cup \{ \u \}$}
          }\ENDFOR

          \STATE{$w_G \gets |S_r|$}
          \STATE{$\omega_G \gets w_G = 0$}
          \STATE{$\Omega_G \gets \land_{r=1}^{k} \omega_F$}
          \WHILE{$\neg \Omega_G$}{
            \FORALL{$u \in S_r$}{
              \IF{$w(u) = 0$}{
                \IF{$i_g(u) = i(u)$}{
                  \STATE{$w_G \gets w_G - 1$}
                }\ELSE{
                  \STATE{$m_v \gets \textsc{Machine-Hash}(h_a, h_b, k, i_p(u))$}
                  \STATE{$send(X_S)[m_v] \gets send(X_S)[m_v] + ( \textsc{pong}, i_p(u), i(u), |g|(u) )$}
                  \COMMENT{Upcast count.}
                }\ENDIF
              }\ELSE{
                \FORALL{$i_v \in C(u)$}{
                  \STATE{$m_v \gets \textsc{Machine-Hash}(h_a, h_b, k, i_v)$}
                  \STATE{$send(X_S)[m_v] \gets send(X_S)[m_v] + ( \textsc{ping}, i_v , i(u), \bot )$}
                  \COMMENT{Downcast query.}
                }\ENDFOR
              }\ENDIF
            }\ENDFOR

            \STATE{$\textsc{Exchange-All}(X_S)$}
            \STATE{$\textsc{Rewind}(X_S)$}
            \STATE{$S_r \gets \emptyset$}

            \FORALL{$(q, i_v, i_u, b) \in recv(X_S)$}{
              \STATE{$v \gets V_r[i_v]$}
              \IF{$q = \textsc{ping}$}{
                \STATE{$w(v) \gets |C(v)|$}
                \STATE{$S_r \gets S_r \cup \{ v \}$}
                \COMMENT{Queue for downcast.}
              }\ELSIF{$q = \textsc{pong}$}{
                \STATE{$w(v) \gets w(v) - 1$}
                \STATE{$|g|(v) \gets |g|(v) + b$}
                \COMMENT{Add to component subtotal.}
                \IF{$w(v) = 0$}{
                  \STATE{$S_r \gets S_r \cup \{ v \}$}
                  \COMMENT{Queue for upcast.}
                }\ENDIF
              }\ENDIF
            }\ENDFOR
            \STATE{$\omega_G \gets w_G = 0$}
            \STATE{$\Omega_G \gets \land_{r=1}^{k} \omega_G$}
          }\ENDWHILE

          \FORALL{$t \in T_r$}{
            \STATE{$send(X_S)[0] \gets send(X_S)[0] + ( i(t), |g|(t) )$}
          }\ENDFOR
          \FORALL{$t \in T_0$}{
            \STATE{$send(X_S)[0] \gets send(X_S)[0] + ( i(t), 0 )$}
          }\ENDFOR
          \STATE{$\textsc{Exchange-One}(X_S, 0)$}
          \COMMENT{Collect component counts at machine with rank 0.}
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      The component census in Algorithm~\ref{alg:component-census} simply performs a downcast and
      convergecast on all the components in the forest, after which it gathers the statistics
      at the machine with rank 0 for reporting to the user. This is a simple post-hoc operation
      with $O(n)$ message complexity.
    }

    \begin{theorem}
      \label{thm:ghs-coco}
      Algorithm~\ref{alg:ghs-coco} determines the connected components in an arbitrary graph
      of $n$ vertices distributed over $k$ machines with communication complexity $O(m + n \log n)$.
    \end{theorem}
    \begin{proof}
      Because the implementation uses a strictly unicast messaging model, the communication complexity
      follows the message complexity. Since each root vertex in the component forest yields
      one MWOE per phase, the worst case scenario is that all the roots align themselves
      in pairwise joins, causing a reduction in components by at least half. This constant reduction
      indicates that the number of phases will be on the order of $O(\log n)$.
      \paragraph{}{
        Each phase consists of a find subphase and merge subphase. The find subphase takes $O(n)$
        messages on account of the complexities of the \textsc{find} downcast, the \textsc{found}
        convergecast, and the \textsc{mwoe} downcast that comprise it. Each operation takes $O(n)$
        messages, so their summation is also $O(n)$. The merge subphase has a simple exchange which
        in the initial worst case is $\frac{n}{2}$ (pairwise mutual join) followed by a simultaneous
        per-component downcast which may hit all nodes in the worst case, so the message cost is
        likewise $O(n)$ for the merge subphase. Over all phases, the total message complexity
        in this regard will be $O(n \log n)$.
      }
      \paragraph{}{
        Suppose that the graph is a complete graph. The total component reduction will occur in
        the first round, but the active edges which have not been traversed in a join must be
        checked regardless. The checking will incur a total message cost of $O(m)$, i.e., the
        number of edges.
      }
      \paragraph{}{
        The post-hoc component census takes $O(n)$ messages. This is readily subsumed into
        the $O(n \log n)$ complexity posed by the find and merge subphases.
      }
      \paragraph{}{
        Depending on the nature of the graph, one of the two aforementioned total message
        complexity terms will dominate. As such, the total message complexity and therefore
        the communication complexity will be the sum of the two terms or $O(m + n \log n)$.
      }
    \end{proof}
  }
}

\section{Results}{
  \subsection{Test Procedures}{
    \paragraph{}{
      Tests to validate correctness were performed locally on a dual-core laptop
      \footnote{2 x Intel(R) Core(TM) i5-6200U CPU @ 2.30GHz.} running Pop!OS.
      \footnote{An Ubuntu 18.04 variant.}
      Tests for which results were collected systematically and graphed were
      done on the UH \texttt{crill} cluster with the following parameters:
      \begin{itemize}
      \item{$n \in 2^{[10,20]}$, the total population size}
      \item{$k \in \{1,2,4,8,16,32\}$, the number of distributed nodes}
      \item{$\epsilon = 0.2$, the threshold error}
      \item{$p$, the existential probability of a given edge,
        \begin{align}
          p &
          \begin{cases}
            < \frac{(1 - \epsilon)\ln n}{n} \\
            = \frac{\ln n}{n} \\
            > \frac{(1 + \epsilon)\ln n}{n} \\
            < \frac{(1 - \epsilon)}{n} \\
            = \frac{1}{n} \\
            > \frac{(1 + \epsilon)}{n} \\
          \end{cases}
        \end{align}
      }
      \end{itemize}
      Each parameter combination was executed on 3 pre-generated graphs
      per regime. The graphs generated with the naive combinatorial edge
      selection scheme only covered graphs with $n \leq 2^{17}$ because of
      the immense time required for generation. However, this should still
      provide enough data points to observe a general trend and make cogent
      comparisons with the much faster but slightly incorrect binomial edge
      selection scheme.
    }
    \paragraph{}{
      Several executables contributed to the testing process:
    }
    \paragraph{\texttt{txt2mpig}}{
      A utility program for converting SNAP edge-centric model text files
      into a compact edge-centric binary format suitable for accessing via MP/IO.
    }
    \paragraph{\texttt{genmpig}}{
      A utility program for generating Erdos-Renyi random graphs and saving
      in a compact edge-centric binary format.
    }
    \paragraph{\texttt{ghs-coco}}{
      A program which reads a compact edge-centric binary format file and
      distributes the vertex-centric equivalent across a $k$-machine context
      and subsequently executes Algorithm~\ref{alg:ghs-coco} on the distributed graph.
    }
    \paragraph{}{
      The reader is directed to the accompanying \texttt{README.md} for
      explicit usage instructions on the various programs as well as
      for a deeper explanation of implementation considerations,
      engineering tradeoffs, and known issues with the programs.
    }
    \paragraph{}{
      It should be noted that the MPI 2.1 standard\autocite{MPI21} and g++-7.2
      was used for development since they were available through the development
      laptop's package system, but the program compiled and ran on the \texttt{crill}
      cluster with g++-5.3.0 and MPI 3.0. The code requires the C++-11 standard.
    }
    \paragraph{}{
      In order to facilitate rapid development, extensive use was made of the C++ STL
      libraries. The vertex input map was a \texttt{std::map}\autocite{map}
      of vertex structures keyed by vertex ID. In each vertex structure, the collection
      GHS tree children was of type \texttt{std::unordered\_set<uint32\_t>}\autocite{unorderedset}.
      The set of neighbors was divided into an active and inactive set using the
      \texttt{std::set<uint32\_t>}\autocite{set} type. Since the sets were ordered,
      the MWOE was always the head of the iterator for the active set.
      An incoming edge map that could have been used to facilitate faster lookup on incoming messages
      was constructed with a \texttt{std::map<std::unordered\_set<uint32\_t>>}, but it played no
      part in the unicast messaging scheme. The component map was a \texttt{std::map}\autocite{map}
      of vertex structures keyed by vertex ID. Its initial collection held all the
      vertices that had at least one incident edge. A separate component map was kept
      for vertices that had no incident edges. Component statistics were gathered at the
      end by iterating over both component maps.
    }
    \paragraph{}{
      Randomized elements\autocite{random} made use of the Mersenne twister PRNG \texttt{std::mt19937}\autocite{mt19337}
      as the basis for all probabilistic distributions. The primary distributions used were
      the \texttt{std::uniform\_int\_distribution}\autocite{uniformintdist},
      \texttt{std::bernoulli\_distribution}\autocite{bernoullidist}, and
      \texttt{std::binomial\_distribution}\autocite{binomialdist}.
    }
  }


  \subsection{Erdos-Renyi Graphs}{
    \paragraph{}{
      Results for experiments on the Erdos-Renyi graphs generated by \texttt{genmpig}
      are given in the following figures. The graphs are divided into group plots characterized
      by edge probability, i.e., $p \in [\frac{1-\epsilon}{n}, \frac{1+\epsilon}{n}]$ or
      $p \in [\frac{(1-\epsilon)\ln n}{n}, \frac{(1+\epsilon)\ln n}{n}]$, and by
      edge selection scheme, i.e., Monte Carlo (MCER) or Las Vegas (LVER) Erdos-Renyi graphs.
    }
    %% Monte Carlo
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in,
              },
              xmode=log,
              ymode=log,
              log basis x=2,
              log basis y=10,
              height=1.5in,
              width=1.5in,
              xlabel=$n$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % 1-
            \linregplots{\footnotesize Load Time}{./er-results/ghs-coco}{.mc.1-}{n}{Tp}
            \linregplots{\footnotesize GHS Time}{./er-results/ghs-coco}{.mc.1-}{n}{Tc}
            \linregplots{\footnotesize Messages}{./er-results/ghs-coco}{.mc.1-}{n}{M}
            \linregplots{\footnotesize Phases}{./er-results/ghs-coco}{.mc.1-}{n}{p}
            % 1
            \linregplots{}{./er-results/ghs-coco}{.mc.1}{n}{Tp}
            \linregplots{}{./er-results/ghs-coco}{.mc.1}{n}{Tc}
            \linregplots{}{./er-results/ghs-coco}{.mc.1}{n}{M}
            \linregplots{}{./er-results/ghs-coco}{.mc.1}{n}{p}
            % 1+
            \linregplots{}{./er-results/ghs-coco}{.mc.1+}{n}{Tp}
            \linregplots{}{./er-results/ghs-coco}{.mc.1+}{n}{Tc}
            \linregplots{}{./er-results/ghs-coco}{.mc.1+}{n}{M}
            \linregplots{}{./er-results/ghs-coco}{.mc.1+}{n}{p}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{1-\epsilon}{n}$}};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{1}{n}$}};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{1+\epsilon}{n}$}};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexity of Algorithm~\ref{alg:ghs-coco} on MCER Graphs, $p \in [\frac{1-\epsilon}{n}, \frac{1+\epsilon}{n}]$}
        \label{fig:ghs-coco-cplx-mc-er1}
      \end{figure}
    }
    \paragraph{}{
      The graph loading and construction times follow the expected decrease as $k$ scales out with the exception of the cases where
      $k = 16$ and $k = 32$. There is likely a machine boundary bottleneck coming into play here since the cases where $1 \leq k \leq 8$
      could all fit on one machine according to the allocation strategy. Communication over the network is bound to induce an additional latency.
    }
    \paragraph{}{
      The execution times for the GHS algorithm actually seem to model the expected decrease as $k$ scales out better than the
      BFS algorithm. The aforementioned exceptions for the higher values of $k$ still apply, likely for the same reasons.
      For the sparse graphs in Figure~\ref{fig:ghs-coco-cplx-mc-er1}, the decrease in execution time is an entire order
      of magnitude. As predicted in the previous trials\autocite[19]{bfs-coco}, removing the known singleton components from active participation
      at the start seems to have had the desired effect. The message complexity is also substantially dropped.
      The reader is directed to Appendix A for a set of graphs directly comparing message and time complexity between
      the two algorithms.
    }
    \paragraph{}{
      Unlike the graphs in the prior report\autocite[11-16]{bfs-coco} which depicted the number of rounds, the graphs here depict the number of
      phases, with a phase consisting of one MWOE search and one merge. Within each subphase, multiple exchanges
      may occur to the order of the depth of the largest component's tree. Seen here, the number of phases is
      clearly a constant fraction of $O(\log_2 n)$, as the phase count barely reaches the neighborhood of 10
      when $n = 2^{20}$. The aggressive pruning of active edges during the merge subphase instead of waiting
      for them to be considered during the MWOE search subphase may have played a pivotal role in achieving this performance.
    }
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in
              },
              xmode=log,
              ymode=log,
              log basis x=2,
              log basis y=10,
              height=1.5in,
              width=1.5in,
              xlabel=$n$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % L-
            \linregplots{\footnotesize Load Time}{./er-results/ghs-coco}{.mc.L-}{n}{Tp}
            \linregplots{\footnotesize GHS Time}{./er-results/ghs-coco}{.mc.L-}{n}{Tc}
            \linregplots{\footnotesize Messages}{./er-results/ghs-coco}{.mc.L-}{n}{M}
            \linregplots{\footnotesize Phases}{./er-results/ghs-coco}{.mc.L-}{n}{p}
            % L
            \linregplots{}{./er-results/ghs-coco}{.mc.L}{n}{Tp}
            \linregplots{}{./er-results/ghs-coco}{.mc.L}{n}{Tc}
            \linregplots{}{./er-results/ghs-coco}{.mc.L}{n}{M}
            \linregplots{}{./er-results/ghs-coco}{.mc.L}{n}{p}
            % L+
            \linregplots{}{./er-results/ghs-coco}{.mc.L+}{n}{Tp}
            \linregplots{}{./er-results/ghs-coco}{.mc.L+}{n}{Tc}
            \linregplots{}{./er-results/ghs-coco}{.mc.L+}{n}{M}
            \linregplots{}{./er-results/ghs-coco}{.mc.L+}{n}{p}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{(1-\epsilon)\ln n}{n}$}};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{\ln n}{n}$}};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{(1+\epsilon)\ln n}{n}$}};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexity of Algorithm~\ref{alg:ghs-coco} on MCER Graphs, $p \in [\frac{(1-\epsilon)\ln n}{n}, \frac{(1+\epsilon)\ln n}{n}]$}
        \label{fig:ghs-coco-cplx-mc-erL}
      \end{figure}
    }
    \paragraph{}{
      The results depicted in Figure~\ref{fig:ghs-coco-cplx-mc-er1} offset the improvements seen in Figure~\ref{fig:ghs-coco-cplx-mc-erL}.
      The empirical time and message complexity is roughly the same if not slightly greater than the BFS algorithm (see Appendix A).
      The likely cause is the unicast nature of the communications in this implementation of the GHS algorithm. Whereas the BFS
      algorithm could utilize broadcast techniques to keep the messages small in many cases, the simultaneous though pair-wise
      communication employed through most of the GHS algorithm seems to have been a detriment. Under this particular implementation,
      the GHS algorithm seems better suited to sparse graphs, as opposed to the previous implementation of the BFS algorithm, which
      performed better with dense graphs\autocite[11,19]{bfs-coco}.
    }
    %% Las Vegas
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in
              },
              xmode=log,
              ymode=log,
              log basis x=2,
              log basis y=10,
              height=1.5in,
              width=1.5in,
              xlabel=$n$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % 1-
            \linregplots{\footnotesize Load Time}{./er-results/ghs-coco}{.vg.1-}{n}{Tp}
            \linregplots{\footnotesize GHS Time}{./er-results/ghs-coco}{.vg.1-}{n}{Tc}
            \linregplots{\footnotesize Messages}{./er-results/ghs-coco}{.vg.1-}{n}{M}
            \linregplots{\footnotesize Phases}{./er-results/ghs-coco}{.vg.1-}{n}{p}
            % 1
            \linregplots{}{./er-results/ghs-coco}{.vg.1}{n}{Tp}
            \linregplots{}{./er-results/ghs-coco}{.vg.1}{n}{Tc}
            \linregplots{}{./er-results/ghs-coco}{.vg.1}{n}{M}
            \linregplots{}{./er-results/ghs-coco}{.vg.1}{n}{p}
            % 1+
            \linregplots{}{./er-results/ghs-coco}{.vg.1+}{n}{Tp}
            \linregplots{}{./er-results/ghs-coco}{.vg.1+}{n}{Tc}
            \linregplots{}{./er-results/ghs-coco}{.vg.1+}{n}{M}
            \linregplots{}{./er-results/ghs-coco}{.vg.1+}{n}{p}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{1-\epsilon}{n}$}};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{1}{n}$}};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{1+\epsilon}{n}$}};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexity of Algorithm~\ref{alg:ghs-coco} on LVER Graphs, $p \in [\frac{1-\epsilon}{n}, \frac{1+\epsilon}{n}]$}
        \label{fig:ghs-coco-cplx-vg-er1}
      \end{figure}
    }
    \paragraph{}{
      The LVER graphs depicted in Figure~\ref{fig:ghs-coco-cplx-vg-er1} exhibit similar behavior to that shown by the
      MCER graphs depicted in Figure~\ref{fig:ghs-coco-cplx-mc-er1}. This again lends support to the rationale behind the MCER edge
      selection scheme as a foundation for a legitimate optimization in graph generation.
    }
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in
              },
              xmode=log,
              ymode=log,
              log basis x=2,
              log basis y=10,
              height=1.5in,
              width=1.5in,
              xlabel=$n$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % L-
            \linregplots{\footnotesize Load Time}{./er-results/ghs-coco}{.vg.L-}{n}{Tp}
            \linregplots{\footnotesize GHS Time}{./er-results/ghs-coco}{.vg.L-}{n}{Tc}
            \linregplots{\footnotesize Messages}{./er-results/ghs-coco}{.vg.L-}{n}{M}
            \linregplots{\footnotesize Phases}{./er-results/ghs-coco}{.vg.L-}{n}{p}
            % L
            \linregplots{}{./er-results/ghs-coco}{.vg.L}{n}{Tp}
            \linregplots{}{./er-results/ghs-coco}{.vg.L}{n}{Tc}
            \linregplots{}{./er-results/ghs-coco}{.vg.L}{n}{M}
            \linregplots{}{./er-results/ghs-coco}{.vg.L}{n}{p}
            % L+
            \linregplots{}{./er-results/ghs-coco}{.vg.L+}{n}{Tp}
            \linregplots{}{./er-results/ghs-coco}{.vg.L+}{n}{Tc}
            \linregplots{}{./er-results/ghs-coco}{.vg.L+}{n}{M}
            \linregplots{}{./er-results/ghs-coco}{.vg.L+}{n}{p}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{(1-\epsilon)\ln n}{n}$}};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{\ln n}{n}$}};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{(1+\epsilon)\ln n}{n}$}};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexity of Algorithm~\ref{alg:ghs-coco} on LVER Graphs, $p \in [\frac{(1-\epsilon)\ln n}{n}, \frac{(1+\epsilon)\ln n}{n}]$}
        \label{fig:ghs-coco-cplx-vg-erL}
      \end{figure}
    }
    \paragraph{}{
      The LVER graphs depicted in Figure~\ref{fig:ghs-coco-cplx-vg-erL} also follow the MCER graphs depicted in Figure~\ref{fig:ghs-coco-cplx-mc-erL}.
      The affinity of this implementation of the GHS algorithm for sparse graphs is likewise underscored.
    }
  }
  \subsection{Real-World Graphs}{
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in
              },
              xmode=log,
              ymode=log,
              log basis x=2,
              log basis y=10,
              height=1.5in,
              width=1.5in,
              xlabel=$k$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % facebook combined
            \linregplots{\footnotesize Load Time}{./rw-results/ghs-coco}{.facebook_combined}{k}{Tp}
            \linregplots{\footnotesize GHS Time}{./rw-results/ghs-coco}{.facebook_combined}{k}{Tc}
            \linregplots{\footnotesize Messages}{./rw-results/ghs-coco}{.facebook_combined}{k}{M}
            \linregplots{\footnotesize Phases}{./rw-results/ghs-coco}{.facebook_combined}{k}{r}
            % ca-AstroPh
            \linregplots{}{./rw-results/ghs-coco}{.ca-AstroPh}{k}{Tp}
            \linregplots{}{./rw-results/ghs-coco}{.ca-AstroPh}{k}{Tc}
            \linregplots{}{./rw-results/ghs-coco}{.ca-AstroPh}{k}{M}
            \linregplots{}{./rw-results/ghs-coco}{.ca-AstroPh}{k}{r}
            % roadNet-TX
            \linregplots{}{./rw-results/ghs-coco}{.roadNet-TX}{k}{Tp}
            \linregplots{}{./rw-results/ghs-coco}{.roadNet-TX}{k}{Tc}
            \linregplots{}{./rw-results/ghs-coco}{.roadNet-TX}{k}{M}
            \linregplots{}{./rw-results/ghs-coco}{.roadNet-TX}{k}{r}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){facebook};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){ca-AstroPh};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){roadNet-TX};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexity of Algorithm~\ref{alg:ghs-coco} on Real-World Graphs}
        \label{fig:ghs-coco-cplx-rw}
      \end{figure}
    }
    \paragraph{}{
      The real world graphs depicted in Figure~\ref{fig:ghs-coco-cplx-rw} exhibit similar
      characteristics as seen with the BFS algorithm. The machine boundary effect is once again evident
      with the uptick in execution time for higher values of $k$. The fact that the graphs are the same
      size lends further credence to this since there is no increase in population size that can be
      charged for the loss of speedup.
    }
    \paragraph{}{
      It should be noted that the allocation strategy in these experiments differed from the BFS experiments.
      At the time of experimentation, the cluster was completely idle, and so the batch scripts
      simply requested 8 CPUs each from four specific nodes (\texttt{crill-101}, \texttt{crill-102},
      \texttt{crill-201}, and \texttt{crill-202}) regardless of actual need to avoid script proliferation
      and simplify the experimentation process.
    }
    \paragraph{}{
      Under this regime, it becomes increasingly clear that the machine boundary effect dominated
      and produced nearly identical results compared with the BFS experiments that had higher
      local utilization throughout. Although the resource allocation within the machine will
      surely have some effect, it was likely dwarfed by the network communication. It is possible
      that the GHS experiments hit the same intra-machine contention and even likely that they hit
      the same intra-job contention since again no explicit constraints were placed on the individual
      processes and the CPUs they occupied. However, the fact that there was no \emph{inter}-job contention
      more strongly supports the machine boundary hypothesis.
    }
  }
  \subsection{Component Statistics}{
    \paragraph{}{
      The following figures depict component size statistics for all the different regimes.
      Plots are made on logarithmic axes for clarity.
    }
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{loglogaxis}[
              xlabel=$n$,
              log basis x=2,
              ylabel=$n_c$,
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend pos=outer north east,
              legend style={font=\tiny},
              legend entries={
                $p = \frac{1-\epsilon}{n}$ (MC),
                $p = \frac{1}{n}$ (MC),
                $p = \frac{1+\epsilon}{n}$ (MC),
                $p = \frac{(1-\epsilon)\ln n}{n}$ (MC),
                $p = \frac{\ln n}{n}$ (MC),
                $p = \frac{(1+\epsilon)\ln n}{n}$ (MC),
                $p = \frac{1-\epsilon}{n}$ (LV),
                $p = \frac{1}{n}$ (LV),
                $p = \frac{1+\epsilon}{n}$ (LV),
                $p = \frac{(1-\epsilon)\ln n}{n}$ (LV),
                $p = \frac{\ln n}{n}$ (LV),
                $p = \frac{(1+\epsilon)\ln n}{n}$ (LV),
                facebook,
                ca-AstroPh,
                roadNet-TX
              }
            ]
            % 1-
            \addplot [green, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.mc.1-.csv};
            % 1
            \addplot [green, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.mc.1.csv};
            % 1+
            \addplot [green, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.mc.1+.csv};
            % L-
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.mc.L-.csv};
            % L
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.mc.L.csv};
            % L+
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.mc.L+.csv};
            % 1-
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.vg.1-.csv};
            % 1
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.vg.1.csv};
            % 1+
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.vg.1+.csv};
            % L-
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.vg.L-.csv};
            % L
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.vg.L.csv};
            % L+
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/ghs-coco.compstats.vg.L+.csv};
            % facebook combined
            \addplot [black, only marks, mark size=0.5] table [x=n, y=cm] {./rw-results/ghs-coco.compstats.facebook_combined.csv};
            % ca-AstroPh
            \addplot [blue, only marks, mark size=0.5] table [x=n, y=cm] {./rw-results/ghs-coco.compstats.ca-AstroPh.csv};
            % roadNet-TX
            \addplot [red, only marks, mark size=0.5] table [x=n, y=cm] {./rw-results/ghs-coco.compstats.roadNet-TX.csv};
          \end{loglogaxis}
        \end{tikzpicture}
        \caption{\footnotesize Component Mean Size for Various Regimes}
        \label{fig:ghs-coco-compmean}
      \end{figure}
    }
    \paragraph{}{
      Figure~\ref{fig:ghs-coco-compmean} reflects exactly the component mean sizes observed in the BFS experiments.
      There is not much more to say beyond what was covered in the previous report\autocite[17-19]{bfs-coco} except that this provides some
      empirical corroboration of the correctness or at least consistency of the GHS implementation with respect
      to the BFS implementation.
    }
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{loglogaxis}[
              xlabel=$n$,
              log basis x=2,
              ylabel=$n_c$,
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend pos=outer north east,
              legend style={font=\tiny},
              legend entries={
                $p = \frac{1-\epsilon}{n}$ (MC),
                $p = \frac{1}{n}$ (MC),
                $p = \frac{1+\epsilon}{n}$ (MC),
                $p = \frac{(1-\epsilon)\ln n}{n}$ (MC),
                $p = \frac{\ln n}{n}$ (MC),
                $p = \frac{(1+\epsilon)\ln n}{n}$ (MC),
                $p = \frac{1-\epsilon}{n}$ (LV),
                $p = \frac{1}{n}$ (LV),
                $p = \frac{1+\epsilon}{n}$ (LV),
                $p = \frac{(1-\epsilon)\ln n}{n}$ (LV),
                $p = \frac{\ln n}{n}$ (LV),
                $p = \frac{(1+\epsilon)\ln n}{n}$ (LV),
                facebook,
                ca-AstroPh,
                roadNet-TX
              }
            ]
            % 1-
            \addplot [green, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.mc.1-.csv};
            % 1
            \addplot [green, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.mc.1.csv};
            % 1+
            \addplot [green, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.mc.1+.csv};
            % L-
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.mc.L-.csv};
            % L
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.mc.L.csv};
            % L+
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.mc.L+.csv};
            % 1-
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.vg.1-.csv};
            % 1
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.vg.1.csv};
            % 1+
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.vg.1+.csv};
            % L-
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.vg.L-.csv};
            % L
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.vg.L.csv};
            % L+
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=f] {./er-results/ghs-coco.compstats.vg.L+.csv};
            % facebook combined
            \addplot [black, only marks, mark size=0.5] table [x=n, y=f] {./rw-results/ghs-coco.compstats.facebook_combined.csv};
            % ca-AstroPh
            \addplot [blue, only marks, mark size=0.5] table [x=n, y=f] {./rw-results/ghs-coco.compstats.ca-AstroPh.csv};
            % roadNet-TX
            \addplot [red, only marks, mark size=0.5] table [x=n, y=f] {./rw-results/ghs-coco.compstats.roadNet-TX.csv};
          \end{loglogaxis}
        \end{tikzpicture}
        \caption{\footnotesize Component Counts for Various Regimes}
        \label{fig:ghs-coco-forest}
      \end{figure}
    }
    \paragraph{}{
      Figure~\ref{fig:ghs-coco-forest} again confirms the statistics seen in the previous report.
    }
  }
}

\section{Conclusions}{
  \paragraph{}{
    It was somewhat surprising to see that the BFS algorithm slightly outperformed
    the GHS algorithm in the experiments on dense graphs. This was largely due to a
    weakness in the implementation, namely the pure reliance on a unicast messaging
    strategy. While the strategy was employed due to time constraints and over concerns
    of ensuring correctness, there are a number of opportunities for improvement.
  }
  \paragraph{}{
    In the first case, broadcast strategies could easily be employed during the MWOE
    search subphase for several of the message types, notably \textsc{mwoe} and
    \textsc{find}. Several bytes per message could have been saved. Moreover, the
    shell of the \texttt{bfs-coco} source served as the genesis for the \texttt{ghs-coco}
    source, and the map of incoming edges was already constructed during execution
    but never used. The incoming edges map would likely need to be supplemented by
    an incoming parents map to achieve the best optimization.
  }
  \paragraph{}{
    Another improvement would be to explore the use of subcommunicators. It may happen
    (and certainly did happen according to debugging runs executed during local
    development) that a machine exhausts its set of local components with active edges
    before other machines finish theirs. It would be better for those machines to
    become in essence ``dark silicon'' at the mere cost of a single message forfeiting
    participation to the savings of innumerable useless participations in the gather
    operations better left to the subset of active machines.
  }
  \paragraph{}{
    Still, the aggressive pruning of known singletons from the start and of joined edges
    during the merge phase paid off dividends in reducing overall phase count and,
    in the case of sparse graphs, empirical message and time complexity. More research
    into the areas suggested for improvement as well as more explicit and considered
    job allocation strategies would likely reap a lucrative benefit, especially
    when one considers the often overlooked cost of energy.
  }
}

\printbibliography

\section{Appendix A}{
  \paragraph{}{
    Result graphs from the \texttt{bfs-coco} experiments on Erdos-Renyi graphs are provided
    here for convenience of comparison with the \texttt{ghs-coco} experiments. The plots
    have been redrawn with logarithmic $x$ and $y$ axes for legibility.
  }
  \paragraph{}{
    Component statistics are not included on account of redundancy. If one compares the graphs from
    the report on the \texttt{bfs-coco} experiments with the component statistics from this report\autocite[18]{bfs-coco},
    one sees the exact same graph. This reproducibility implies an empirical corroboration of the
    correctness of both implementations or, at the very least, consistent wrongness.
  }

  %% Monte Carlo
  \paragraph{}{
    \begin{figure}
      \begin{tikzpicture}
        \footnotesize
        \begin{groupplot}[
            group style={
              group size=4 by 3,
              xlabels at=edge bottom,
              ylabels at=edge left,
              vertical sep=0.5in
            },
            xmode=log,
            ymode=log,
            log basis x=2,
            log basis y=10,
            height=1.5in,
            width=1.5in,
            xlabel=$n$,
            ylabel=$t$ (ns),
            tick label style={font=\tiny},
            label style={font=\tiny},
            legend style={font=\tiny, legend columns=6},
            legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
            legend to name=nprocs
          ]
          % 1-
          \linregplots{\footnotesize T (GHS)}{./er-results/ghs-coco}{.mc.1-}{n}{Tc}
          \linregplots{\footnotesize T (BFS)}{./er-results/bfs-coco}{.mc.1-}{n}{Tc}
          \linregplots{\footnotesize M (GHS)}{./er-results/ghs-coco}{.mc.1-}{n}{M}
          \linregplots{\footnotesize M (BFS)}{./er-results/bfs-coco}{.mc.1-}{n}{M}
          % 1
          \linregplots{}{./er-results/ghs-coco}{.mc.1}{n}{Tc}
          \linregplots{}{./er-results/bfs-coco}{.mc.1}{n}{Tc}
          \linregplots{}{./er-results/ghs-coco}{.mc.1}{n}{M}
          \linregplots{}{./er-results/bfs-coco}{.mc.1}{n}{M}
          % 1+
          \linregplots{}{./er-results/ghs-coco}{.mc.1+}{n}{Tc}
          \linregplots{}{./er-results/bfs-coco}{.mc.1+}{n}{Tc}
          \linregplots{}{./er-results/ghs-coco}{.mc.1+}{n}{M}
          \linregplots{}{./er-results/bfs-coco}{.mc.1+}{n}{M}
        \end{groupplot}
        \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{1-\epsilon}{n}$}};
        \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{1}{n}$}};
        \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{1+\epsilon}{n}$}};
        \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
      \end{tikzpicture}
      \caption{\footnotesize Empirical Complexities on MCER Graphs, $p \in [\frac{1-\epsilon}{n}, \frac{1+\epsilon}{n}]$}
      \label{fig:bfs-coco-cplx-mc-er1}
    \end{figure}
  }
  \paragraph{}{
    \begin{figure}
      \begin{tikzpicture}
        \footnotesize
        \begin{groupplot}[
            group style={
              group size=4 by 3,
              xlabels at=edge bottom,
              ylabels at=edge left,
              vertical sep=0.5in
            },
            xmode=log,
            ymode=log,
            log basis x=2,
            log basis y=10,
            height=1.5in,
            width=1.5in,
            xlabel=$n$,
            ylabel=$t$ (ns),
            tick label style={font=\tiny},
            label style={font=\tiny},
            legend style={font=\tiny, legend columns=6},
            legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
            legend to name=nprocs
          ]
          % L-
          \linregplots{\footnotesize T (GHS)}{./er-results/ghs-coco}{.mc.L-}{n}{Tc}
          \linregplots{\footnotesize T (BFS) }{./er-results/bfs-coco}{.mc.L-}{n}{Tc}
          \linregplots{\footnotesize M (GHS)}{./er-results/ghs-coco}{.mc.L-}{n}{M}
          \linregplots{\footnotesize M (BFS)}{./er-results/bfs-coco}{.mc.L-}{n}{M}
          % L
          \linregplots{}{./er-results/ghs-coco}{.mc.L}{n}{Tc}
          \linregplots{}{./er-results/bfs-coco}{.mc.L}{n}{Tc}
          \linregplots{}{./er-results/ghs-coco}{.mc.L}{n}{M}
          \linregplots{}{./er-results/bfs-coco}{.mc.L}{n}{M}
          % L+
          \linregplots{}{./er-results/ghs-coco}{.mc.L+}{n}{Tc}
          \linregplots{}{./er-results/bfs-coco}{.mc.L+}{n}{Tc}
          \linregplots{}{./er-results/ghs-coco}{.mc.L+}{n}{M}
          \linregplots{}{./er-results/bfs-coco}{.mc.L+}{n}{M}
        \end{groupplot}
        \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{(1-\epsilon)\ln n}{n}$}};
        \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{\ln n}{n}$}};
        \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{(1+\epsilon)\ln n}{n}$}};
        \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
      \end{tikzpicture}
      \caption{\footnotesize Empirical Complexities on MCER Graphs, $p \in [\frac{(1-\epsilon)\ln n}{n}, \frac{(1+\epsilon)\ln n}{n}]$}
      \label{fig:bfs-coco-cplx-mc-erL}
    \end{figure}
  }
  %% Las Vegas
  \paragraph{}{
    \begin{figure}
      \begin{tikzpicture}
        \footnotesize
        \begin{groupplot}[
            group style={
              group size=4 by 3,
              xlabels at=edge bottom,
              ylabels at=edge left,
              vertical sep=0.5in
            },
            xmode=log,
            ymode=log,
            log basis x=2,
            log basis y=10,
            height=1.5in,
            width=1.5in,
            xlabel=$n$,
            ylabel=$t$ (ns),
            tick label style={font=\tiny},
            label style={font=\tiny},
            legend style={font=\tiny, legend columns=6},
            legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
            legend to name=nprocs
          ]
          % 1-
          \linregplots{\footnotesize T (GHS)}{./er-results/ghs-coco}{.vg.1-}{n}{Tc}
          \linregplots{\footnotesize T (BFS)}{./er-results/bfs-coco}{.vg.1-}{n}{Tc}
          \linregplots{\footnotesize M (GHS)}{./er-results/ghs-coco}{.vg.1-}{n}{M}
          \linregplots{\footnotesize M (BFS)}{./er-results/bfs-coco}{.vg.1-}{n}{M}
          % 1
          \linregplots{}{./er-results/ghs-coco}{.vg.1}{n}{Tc}
          \linregplots{}{./er-results/bfs-coco}{.vg.1}{n}{Tc}
          \linregplots{}{./er-results/ghs-coco}{.vg.1}{n}{M}
          \linregplots{}{./er-results/bfs-coco}{.vg.1}{n}{M}
          % 1+
          \linregplots{}{./er-results/ghs-coco}{.vg.1+}{n}{Tc}
          \linregplots{}{./er-results/bfs-coco}{.vg.1+}{n}{Tc}
          \linregplots{}{./er-results/ghs-coco}{.vg.1+}{n}{M}
          \linregplots{}{./er-results/bfs-coco}{.vg.1+}{n}{M}
        \end{groupplot}
        \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{1-\epsilon}{n}$}};
        \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{1}{n}$}};
        \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{1+\epsilon}{n}$}};
        \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
      \end{tikzpicture}
      \caption{\footnotesize Empirical Complexities on LVER Graphs, $p \in [\frac{1-\epsilon}{n}, \frac{1+\epsilon}{n}]$}
      \label{fig:bfs-coco-cplx-vg-er1}
    \end{figure}

    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in
              },
              xmode=log,
              ymode=log,
              log basis x=2,
              log basis y=10,
              height=1.5in,
              width=1.5in,
              xlabel=$n$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % L-
            \linregplots{\footnotesize T (GHS)}{./er-results/ghs-coco}{.vg.L-}{n}{Tc}
            \linregplots{\footnotesize T (BFS)}{./er-results/bfs-coco}{.vg.L-}{n}{Tc}
            \linregplots{\footnotesize M (GHS)}{./er-results/ghs-coco}{.vg.L-}{n}{M}
            \linregplots{\footnotesize M (BFS)}{./er-results/bfs-coco}{.vg.L-}{n}{M}
            % L
            \linregplots{}{./er-results/ghs-coco}{.vg.L}{n}{Tc}
            \linregplots{}{./er-results/bfs-coco}{.vg.L}{n}{Tc}
            \linregplots{}{./er-results/ghs-coco}{.vg.L}{n}{M}
            \linregplots{}{./er-results/bfs-coco}{.vg.L}{n}{M}
            % L+
            \linregplots{}{./er-results/ghs-coco}{.vg.L+}{n}{Tc}
            \linregplots{}{./er-results/bfs-coco}{.vg.L+}{n}{Tc}
            \linregplots{}{./er-results/ghs-coco}{.vg.L+}{n}{M}
            \linregplots{}{./er-results/bfs-coco}{.vg.L+}{n}{M}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{(1-\epsilon)\ln n}{n}$}};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{\ln n}{n}$}};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{(1+\epsilon)\ln n}{n}$}};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexities on LVER Graphs, $p \in [\frac{(1-\epsilon)\ln n}{n}, \frac{(1+\epsilon)\ln n}{n}]$}
        \label{fig:bfs-coco-cplx-vg-erL}
      \end{figure}
    }
  }
  \paragraph{}{
    \begin{figure}
      \begin{tikzpicture}
        \footnotesize
        \begin{groupplot}[
            group style={
              group size=4 by 3,
              xlabels at=edge bottom,
              ylabels at=edge left,
              vertical sep=0.5in
            },
            xmode=log,
            ymode=log,
            log basis x=2,
            log basis y=10,
            height=1.5in,
            width=1.5in,
            xlabel=$k$,
            ylabel=$t$ (ns),
            tick label style={font=\tiny},
            label style={font=\tiny},
            legend style={font=\tiny, legend columns=6},
            legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
            legend to name=nprocs
          ]
          % facebook combined
          \linregplots{\footnotesize T (GHS)}{./rw-results/ghs-coco}{.facebook_combined}{k}{Tc}
          \linregplots{\footnotesize T (BFS)}{./rw-results/bfs-coco}{.facebook_combined}{k}{Tc}
          \linregplots{\footnotesize M (GHS)}{./rw-results/ghs-coco}{.facebook_combined}{k}{M}
          \linregplots{\footnotesize M (BFS)}{./rw-results/bfs-coco}{.facebook_combined}{k}{M}
          % ca-AstroPh
          \linregplots{}{./rw-results/ghs-coco}{.ca-AstroPh}{k}{Tc}
          \linregplots{}{./rw-results/ghs-coco}{.ca-AstroPh}{k}{Tc}
          \linregplots{}{./rw-results/ghs-coco}{.ca-AstroPh}{k}{M}
          \linregplots{}{./rw-results/bfs-coco}{.ca-AstroPh}{k}{M}
          % roadNet-TX
          \linregplots{}{./rw-results/ghs-coco}{.roadNet-TX}{k}{Tc}
          \linregplots{}{./rw-results/ghs-coco}{.roadNet-TX}{k}{Tc}
          \linregplots{}{./rw-results/ghs-coco}{.roadNet-TX}{k}{M}
          \linregplots{}{./rw-results/bfs-coco}{.roadNet-TX}{k}{M}
        \end{groupplot}
        \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){facebook};
        \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){ca-AstroPh};
        \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){roadNet-TX};
        \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
      \end{tikzpicture}
      \caption{\footnotesize Empirical Complexities on Real-World Graphs}
      \label{fig:bfs-coco-cplx-rw}
    \end{figure}
  }
}

\end{document}
