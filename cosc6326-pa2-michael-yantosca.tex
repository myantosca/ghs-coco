\documentclass[11pt,epsf]{article}
\usepackage{amssymb,amsmath,amsthm,amsfonts,mathrsfs,color}
\usepackage{epsfig}
\usepackage{latexsym}
\usepackage{verbatim}
\usepackage{setspace}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{algorithmicext}
\usepackage{ifthen}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}
\usepackage[utf8]{luainputenc}
\usepackage[bibencoding=utf8,backend=biber]{biblatex}
\addbibresource{cosc6326-pa2-michael-yantosca.bib}
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{{\footnotesize{COSC6326 PA 2}}}
\rhead{{\footnotesize{Michael Yantosca}}}

\usepackage{longtable}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepgfplotslibrary{external}
\usepgfplotslibrary{statistics}
\usepgfplotslibrary{groupplots}
\usetikzlibrary{pgfplots.groupplots, external}
\tikzexternalize[]
\pgfplotsset{
  tick label style={font=\footnotesize},
  label style={font=\small},
  legend style={font=\small},
  compat=newest
}
\pgfplotstableset{
  col sep=comma,
  begin table=\begin{longtable},
  end table=\end{longtable},
  every head row/.append style={after row=\endhead}
}

\newtheorem{fact}{Fact}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{example}{Example}
\newtheorem{observation}{Observation}
\newtheorem{exercise}{Exercise}
\newtheorem{statement}{Statement}
\newtheorem{problem}{Problem}

\newcommand{\TODO}[0]{\textbf{\color{red}{TODO}}}

% \linregplots{title}{prefix}{suffix}{x}{y}
\newcommand{\linregplots}[5]{
  \nextgroupplot[title=#1]
  \addplot [red, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k1#3.csv};
  \addplot [red, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k1#3.csv};
  \addplot [blue, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k2#3.csv};
  \addplot [blue, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k2#3.csv};
  \addplot [green, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k4#3.csv};
  \addplot [green, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k4#3.csv};
  \addplot [orange, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k8#3.csv};
  \addplot [orange, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k8#3.csv};
  \addplot [purple, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k16#3.csv};
  \addplot [purple, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k16#3.csv};
  \addplot [brown, only marks, mark size=0.5] table [x=#4, y=#5] {#2.k32#3.csv};
  \addplot [brown, no markers] table [x=#4,y={create col/linear regression={y=#5}}] {#2.k32#3.csv};
}

\date{}
\title{COSC6326 Programming Assignment 2}
\author{Michael Yantosca}
\begin{document}
\maketitle
\tableofcontents

\section{Introduction}{
  \paragraph{}{
    The study of graph connectivity can yield insight into problem spaces in communication
    efficiency. Knowing where links are in a given graph can inform routing and help determine
    the best information dissemination strategies. Starting from a clean-room environment with
    graphs whose edges are a function of randomness, universal properties about
    graph connectivity may be uncovered that can then be applied to real-world examples
    to further refine the theory. In this set of experiments, the discovery of
    connected components through the use of breadth-first search (BFS) is explored both
    on Erdos-Renyi graphs\autocite[5]{pa2spec} and real world datasets from the SNAP database\autocite{SNAP}. A novel
    but incomplete method of Erdos-Renyi graph generation is proposed for improvements in
    generation efficiency.
  }
}

\section{Analysis}{
  \subsection{\texttt{text2mpig}}{
    \paragraph{}{
      The graph representations available from the SNAP database\autocite{SNAP} are in a textual format
      over which is difficult to efficiently parallelize data access. Whereas one could serially access
      the data from a predetermined root node and thereafter distribute it to other participating nodes,
      the loading time might be reduced if all the nodes could participate in the loading by each focusing
      on a subset of the data to be loaded. At rest, the vertex-centric model has a disadvantage against
      the edge-centric model since the variability of node composition in the absence of a guarantee of
      isomorphism or regularity necessitates additional header information on top of the unevenness of
      distribution. The optimal distribution of data cannot be determined \emph{a priori} by an unbiased
      strategy.
    }
    \paragraph{}{
      Conversely, the read load of an edge-centric model can be evenly distributed when
      encoded in an efficient packed binary format since all edges are symmetric with each
      other provided that the vertex labels can be expressed in a fixed-width format. It is
      likely for this reason that the SNAP database provides models as a set of edges. A
      little preprocessing work up front could yield dividends, even when the algorithm
      model is vertex-centric. To this end, the \texttt{txt2mpig} utility was created with
      the additional benefit of a decrease in storage costs at rest since each node label
      only requires 4 bytes (each edge 8 bytes).
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Text-To-MPI-Graph}, Algorithm for Converting Edge-Centric Text Model to Compact Edge-Centric Form}
        \begin{algorithmic}
          \REQUIRE{$e_B$, the number of edges per output block per machine}
          \REQUIRE{$k$, the number of participating nodes}
          \REQUIRE{$r$, the participating process rank}
          \STATE{Open the output file for writing each edge $(u,v)$ as <$u$|$v$>.}
          \WHILE{\neg \textsc{eof}}{
            \IF{$r = 0$}{
              \STATE{Read a line of text.}
              \IF{the line is of the form ``$u$ $v$''}{
                \STATE{Add <$u$|$v$> to the binary read buffer.}
              }\ELSE{
                \STATE{Discard the line.}
              }\ENDIF
              \STATE{Check for \textsc{eof}.}
            }\ENDIF
            \STATE{Broadcast the updated read offset to all processes.}
            \STATE{Broadcast the \textsc{eof} status to all processes.}
            \IF{read buffer is at capacity ($16e_Bk$ bytes) or \textsc{eof}}{
              \STATE{Wait for the previous non-blocking write to finish.}
              \STATE{Scatter the read buffer evenly among all the processes.}
              \STATE{Start a non-blocking write at an offset linearly scaled by $r$ to avoid contention.}
              \STATE{Increment the absolute write offset for the next pass.}
              \STATE{Tare the read buffer offset.}
            }\ENDIF
          }\ENDWHILE
          \STATE{Wait for any outstanding disk writes.}
          \STATE{Close the output file.}
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      The resulting edge-centric binary files exhibited expected compression by virtue
      of being more efficient on average in terms of label storage.
      \begin{longtable}{l|c|c}
        \textbf{Real-World Graph} & \textbf{Text File Size} & \textbf{Binary File Size} \\
        facebook\_combined & 835K & 690K \\
        ca-AstroPh & 5.1M & 3.1M \\
        roadNet-TX & 57M & 30M \\
      \end{longtable}
    }
  }

  \subsection{\texttt{genmpig}}{
    \paragraph{}{
      The same binary file format could easily be generated in a stream-processing fashion
      for an Erdos-Renyi probabilistic graph. Two variants of the algorithm were created,
      largely out of a necessity to find a more time-efficient graph generator.
      Unfortunately, as the names suggest, the latter algorithm sacrificed some
      correctness for the sake of speed.
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Generate-MPI-Graph}, Distributed Algorithm for Generating an Erdos-Renyi Graph Stored in Compact Edge-Centric Form}
        \begin{algorithmic}
          \REQUIRE{$e_B$, edges per output block per machine}
          \REQUIRE{$p$, the probability of any given edge}
          \REQUIRE{$n$, the graph population size (nodes)}
          \REQUIRE{$r$, the process rank}
          \STATE{Seed a PRNG for a Bernoulli distribution with decision probability $p$.}
          \STATE{Open the output file for writing each edge $(u,v)$ as <$u$|$v$>.}
          \FOR{$i \in [0,n-1]$}{
            \STATE{$u \gets i + r$}
            \IF{$u < n$}{
              \STATE{Add an ``edge'' $(u,u)$ to ensure inclusion of $u$ even as a singleton.}
              \IF{write buffer has reached capacity}{
                \STATE{Dump the buffer via a shared file pointer.}
                \STATE{Tare the write buffer offset.}
              }\ENDIF
              \STATE{Generates incident edges from $u$ according to Algorithm~\ref{alg:chooselv} or Algorithm~\ref{alg:choosemc}}
            }\ENDIF
          }\ENDFOR
          \STATE{Dump remainder of write buffer if partially full.}
          \STATE{Wait for final write.}
          \STATE{Close the output file.}
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Choose-Edges-Las-Vegas}, Naive Edge Selection Algorithm with Guaranteed Correctness}
        \label{alg:chooselv}
        \begin{algorithmic}
          \REQUIRE{$u$, the source node label}
          \REQUIRE{$P_{E}$, a Bernoulli distribution with decision probability $p$}
          \FOR{$v \in [u + 1, n - 1]$}{
            \STATE{Take sample $E_{uv}$ from space with distribution $P_{E}$.}
            \IF{$E_{uv} = 1$}{
              \STATE{Add <$u$|$v$> to the binary write buffer.}
              \IF{write buffer has reached capacity}{
                \STATE{Dump the buffer via a shared file pointer.}
                \STATE{Tare the write buffer offset.}
              }\ENDIF
            }\ENDIF
          }\ENDFOR
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Choose-Edges-Monte-Carlo}, Time-Efficient Edge Selection Algorithm with Suboptimal Correctness}
        \label{alg:choosemc}
        \begin{algorithmic}
          \REQUIRE{$u$, the source node label}
          \REQUIRE{$P_v$, a uniform distribution over $[u+1, n-1]$}
          \REQUIRE{$B_E$, a $Bin(n - 1 - u, p)$ distribution}
          \STATE{Sample $B_E$ to get a number of successful edge creations $E_u$.}
          \FOR{$e \in [0, E_u-1]$}{
            \STATE{$v \gets \text{ a sample from } P_v$}
            \STATE{Add <$u$|$v$> to the binary write buffer.}
            \IF{write buffer has reached capacity}{
              \STATE{Dump the buffer via a shared file pointer.}
              \STATE{Tare the write buffer offset.}
            }\ENDIF
          }\ENDFOR
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      The asymptotic time benefits of Algorithm~\ref{alg:choosemc} over
      Algorithm~\ref{alg:chooselv} are fairly apparent, particularly when one considers
      the overhead necessary to generate a combinatorial set of coin flips.
      However, the use of the uniform distribution to choose an $O(np)$ sequence
      of numbers runs the risk of sampling duplicate edges. Even when $p = 1$,
      the algorithm did not always generate a complete graph. A simple shuffle
      algorithm would be a better choice if not for the onerous \emph{space}
      requirements at the data scales under consideration.
    }
  }

  \subsection{\texttt{bfs-coco}}{
    \paragraph{}{
      The BFS algorithm for finding connected components is given below in Algorithm~\ref{alg:bfs-coco}.
      For the sake of legibility, several helper functions and procedures are abstracted out
      from the main body and presented following the main algorithm. In the implementation,
      only Algorithm~\ref{alg:exchange} is actually abstracted out into a separate function.
      All other sub-algorithms run within the main context to avoid unnecessary function call overhead,
      particularly Algorithm~\ref{alg:machine-hash}.
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{BFS-Connected-Components}, Distributed BFS Algorithm for Determining Connected Components in an Arbitrary Graph}
        \label{alg:bfs-coco}
        \begin{algorithmic}
          \REQUIRE{$k$, the process/machine rank}
          \REQUIRE{$F$, the binary-format, edge-centric graph model input file}
          \IF{$r = 0$}{
            \STATE{Sample $h_a$ from an independent uniform distribution $U_a$ over $[1,M_{61} - 1]$.}
            \STATE{Sample $h_b$ from an independent uniform distribution $U_b$ over $[0,M_{61} - 1]$.}
          }\ENDIF
          \STATE{Distribute $h_a$ and $h_b$ to all machines.}
          \STATE{$(V_{in}, E_{in}) \gets \textsc{Load-Edge-To-Vertex-Centric}(F, k)$}

          \STATE{Initialize exchange info $X_B$ for the broadcast phase.}
          \STATE{Initialize exchange info $X_U$ for the upcast phase.}
          \STATE{$T$ \gets \emptyset}
          \COMMENT{component set}
          \STATE{$B$ \gets \emptyset}
          \COMMENT{broadcast vertex set}
          \STATE{$U$ \gets \emptyset}
          \COMMENT{upcast vertex set}
          \STATE{$V_{out} \gets \emptyset$}
          \COMMENT{finished vertex set}
          \STATE{$\omega_{r} \gets V_{in} = \emptyset$}
          \COMMENT{local termination condition}
          \STATE{$\Omega \gets \land_{r=1}^{k} \omega_{r}$}
          \COMMENT{global termination condition}
          \WHILE{$\neg \Omega$}{
            \STATE{$i_{g,r} \gets \min\limits_{v \in V_{in}} i(v)$}
            \STATE{$i_g \gets \min\limits_{r=0}^{k-1} i_{g,r}$}
            \STATE{$m_g \gets \textsc{Machine-Hash}(h_a, h_b, k, i_g)$}
            \STATE{$|g|_r \gets 0$}
            \STATE{$|g| \gets 0$}
            \IF{$r = m_g$}{
              \STATE{$s(V_{in}[i_g]) \gets \textsc{broadcast}$}
              \STATE{$B \gets B \cup \{ V_{in}[i_g] \}$}
            }\ENDIF
            \WHILE{$|g| = 0$}{
              \STATE{Execute \textsc{BFS-Connected-Components-Broadcast} phase.}
              \STATE{Execute \textsc{BFS-Connected-Components-Upcast} phase.}
              \STATE{$|g| \gets \max_{r=0}^{k-1} |g|_r$}
            }\ENDWHILE
            \STATE{$\omega_{r} \gets V_{in} = \emptyset$}
            \STATE{$\Omega \gets \land_{r=1}^{k} \omega_{r}$}
          }\ENDWHILE
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Exchange}, Machine-wise Exchange of Information}
        \label{alg:exchange}
        \begin{algorithmic}
          \REQUIRE{$X_i$, exchange information for machine $i$}
          \REQUIRE{$send(X_i)[m]$, send buffer targeting machine $m$ from machine $i$}
          \REQUIRE{$recv(X_m)$, receive buffer for machine $m$}
          \REQUIRE{$k$, the number of machines participating}
          \FOR{$m \in [0,k-1]$}{
            \STATE{Machine $m$ gathers $len(send(X_i)[m])$ from all machines.}
            \STATE{Machine $m$ allocates $\sum_{i=0}^{k-1} len(send(X_i)[m])$ for $recv(X_m)$.}
            \STATE{$recv(X_m) \gets concat(\{ send(X_i)[m] \ | \  0 \leq i < k \})$}
          }\ENDFOR
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Machine-Hash}, Universal Hashing Function for Mapping Vertices to Machines}
        \label{alg:machine-hash}
        \begin{algorithmic}
          \REQUIRE{$M_{61}$, the Mersenne prime $2^{61} - 1$}
          \REQUIRE{$h_a$, an integer in the range $[1,M_{61} - 1]$}
          \REQUIRE{$h_b$, an integer in the range $[0,M_{61} - 1]$}
          \REQUIRE{$k$, the number of machines}
          \REQUIRE{$i_v$, the vertex id to be hashed to some machine $m_h$}
          \RETURN{$((h_ai_v + h_b) \mod M_{61}) \mod k$}
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{Load-Edge-To-Vertex-Centric}, Distributed Algorithm for Loading an Edge-Centric Storage Model and Converting to a Vertex-Centric Memory Model}
        \label{alg:le2v}
        \begin{algorithmic}
          \REQUIRE{$F$, the binary-format, edge-centric graph model input file}
          \STATE{Initialize edge exchange info $X_e$.}
          \STATE{Open $F$ for reading.}
          \STATE{$S_F \gets $ the input file size}
          \STATE{$|E| \gets S_F / 8$}
          \STATE{$|E|_{\bar{k}} \gets S_F / k$}
          \STATE{$|E|_r \gets S_F \mod k$}
          \IF{$r < |E|_r$}{
            \STATE{$|E|_k \gets |E|_{\bar{k}} + 1$}
          }
          \ELSE{
            \STATE{$|E|_k \gets |E|_{\bar{k}}$}
          }\ENDIF
          \STATE{Read $|E|_k$ bytes with offset proportional to $k$ into $E_r$.}
          \STATE{Close $F$.}
          \FOR{$i \in [0, |E|_k-1]$}{
            \STATE{$e_{uv} \gets (E_r[2i],E_r[2i+1])$}
            \STATE{$e_{vu} \gets (E_r[2i+1],E_r[2i])$}
            \STATE{$machine_u \gets \textsc{Machine-Hash}(h_a, h_b, k, e_{uv}[0])$}
            \STATE{$machine_v \gets \textsc{Machine-Hash}(h_a, h_b, k, e_{vu}[0])$}
            \STATE{Add $e_{uv}$ to the exchange buffer for $machine_u$.}
            \STATE{Add $e_{vu}$ to the exchange buffer for $machine_v$.}
          }\ENDFOR
          \STATE{\textsc{Exchange}($X_e$)}
          \STATE{$E_{in} \gets emptyset$}
          \FOR{$(i_u,i_v) \in E_{rcvd}$}{
            \STATE{$u \gets V_{in}[i_u]$}
            \IF{$u = \bot$}{
              \STATE{$u \gets \{ i = u, i_p = u, i_g = u, |g| = 1, s = \textsc{ungrouped}, w = 0, N = \emptyset, C = \emptyset$ \}}
              \STATE{$V_{in}[i_u] \gets u$}
            }\ENDIF
            \IF{$i_u \neq i_v$}{
              \STATE{$N(u) \gets N(u) \cup \{ i_v \}$}
              \IF{$i_v \notin E_{in}$}{
                \STATE{$E_{in}[i_v] \gets \emptyset$}
              }\ENDIF
              \STATE{$E_{in}[i_v] \gets E_{in}[i_v] \cup \{ i_u \}$}
            }\ENDIF
          }\ENDFOR
          \FOR{$u \in V_{in}$}{
            \STATE{$w(u) \gets |N(u)|$}
            \COMMENT{Avoid double-counting neighbors if duplicates in edge storage.}
          }\ENDFOR
          \RETURN{$(V_{in}, E_{in})$}
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{BFS-Connected-Components-Broadcast}, Broadcast Phase of Algorithm~\ref{alg:bfs-coco} }
        \label{alg:bfs-coco-broadcast}
        \begin{algorithmic}
          \FORALL{$u \in B$}{
            \STATE{$s(u) \gets \textsc{pending}$}
            \FORALL{$i_v \in N(u)$}{
              \STATE{$m_v \gets \textsc{Machine-Hash}(h_a, h_b, k,i_v)$}
              \STATE{$send(X_B)[m_v] \gets send(X_B)[m_v] \cup \{ i(u) \}$}
            }\ENDFOR
            \IF{$w(u) = 0$}{
              \STATE{$U \gets U \cup \{ u \}$}
            }\ENDIF
          }\ENDFOR
          \STATE{$\textsc{Exchange}(X_B)$}
          \STATE{$\textsc{Rewind}(X_B)$}
          \STATE{$B \gets \emptyset$}
          \FORALL{$i_u \in recv(X_B)$}{
            \STATE{$m_u \gets \textsc{Machine-Hash}(h_a, h_b, k,i_u)$}
            \FORALL{$i_v \in E_{in}[i_u]$}{
              \STATE{$v \gets V_{in}[i_v]$}
              \IF{$s(v) = \textsc{ungrouped}$}{
                \STATE{$i_p(v) \gets i_u$}
                \STATE{$s(v) \gets \textsc{broadcast}$}
                \STATE{$i_g(v) \gets i_g$}
                \STATE{$B \gets B \cup \{ v \}$}
              }\ELSE{
                \STATE{$send(X_U)[m_u] \gets send(X_U)[m_u] + (i_u, i(v), 0)$}
              }\ENDIF
            }\ENDFOR
          }\ENDFOR
        \end{algorithmic}
      \end{algorithm}
    }
    \paragraph{}{
      \begin{algorithm}
        \footnotesize
        \caption{\textsc{BFS-Connected-Components-Upcast}, Upcast Phase of Algorithm~\ref{alg:bfs-coco} }
        \label{alg:bfs-coco-upcast}
        \begin{algorithmic}
          \FORALL{$u \in U$}{
            \STATE{$s(u) \gets \textsc{FINISHED}$}
            \IF{$i(u) = i_g$}{
              \STATE{$|g|_r \gets |g|(u)$}
            }\ELSE{
              \STATE{$m_p \gets \textsc{Machine-Hash}(h_a, h_b, k,i_p(u))$}
              \STATE{$send(X_U)[m_p] \gets send(X_U)[m_p] + (i_p(u), i(u), |g|(u))$}
              \STATE{$V_{out} \gets V_{out} \cup \{ u \}$}
            }\ENDIF
          }\ENDFOR
          \STATE{$U \gets \emptyset$}
          \STATE{$\textsc{Exchange}(X_U)$}
          \STATE{$\textsc{Rewind}(X_U)$}
          \FORALL{$(i_v, i_u, |g|_u) \in recv(X_U)$}{
            \STATE{$v \gets V_{in}[i_v]$}
            \STATE{$|g|(v) \gets |g|(v) + |g|_u$}
            \IF{$|g|_u > 0$}{
              \STATE{$C(v) \gets C(v) \cup \{ i_u \}$}
            }\ENDIF
            \STATE{$w(v) \gets w(v) - 1$}
            \IF{$w(v) = 0$}{
              \STATE{$U \gets U \cup \{ v \}$}
            }\ENDIF
          }\ENDFOR
          \STATE{$V_{in} \gets V_{in} \setminus V_{out}$}
        \end{algorithmic}
      \end{algorithm}
    }

    \begin{theorem}
      \label{thm:bfs-coco}
      Algorithm~\ref{alg:bfs-coco} determines the connected components in an arbitrary graph
      of $n$ vertices distributed over $k$ machines with communication complexity $O(nk + m))$.
    \end{theorem}
    \begin{proof}
      Each node must serve as either a BFS tree root or subroot or leaf. Each top-level
      root found incurs by necessity $O(k)$ meta-messages of coordination since no
      optimizations are made in the singleton case. In the event that the graph is
      completely disconnected, this becomes $O(nk)$ total meta-messages.
      \paragraph{}{
        Suppose that the graph is connected to some degree. Each edge must be traversed by the
        BFS: once during the broadcast phase, and once during the upcast phase. Thus,
        the message count in this respect is $O(m)$.
      }
      \paragraph{}{
        The communication complexity follows by simple addition. Whichever term is greater
        will necessarily dominate. In highly connected graphs, $m$ will dominate. In
        sparsely connected grpahs, $nk$ will dominate.
      }
    \end{proof}
  }
}

\section{Results}{
  \subsection{Test Procedures}{
    \paragraph{}{
      Tests to validate correctness were performed locally on a dual-core laptop
      \footnote{2 x Intel(R) Core(TM) i5-6200U CPU @ 2.30GHz.} running Pop!OS.
      \footnote{An Ubuntu 18.04 variant.}
      Tests for which results were collected systematically and graphed were
      done on the UH \texttt{crill} cluster with the following parameters:
      \begin{itemize}
      \item{$n \in 2^{[10,20]}$, the total population size}
      \item{$k \in \{1,2,4,8,16,32\}$, the number of distributed nodes}
      \item{$\epsilon = 0.2$, the threshold error}
      \item{$p$, the existential probability of a given edge,
        \begin{align}
          p &
          \begin{cases}
            < \frac{(1 - \epsilon)\ln n}{n} \\
            = \frac{\ln n}{n} \\
            > \frac{(1 + \epsilon)\ln n}{n} \\
            < \frac{(1 - \epsilon)}{n} \\
            = \frac{1}{n} \\
            > \frac{(1 + \epsilon)}{n} \\
          \end{cases}
        \end{align}
      }
      \end{itemize}
      Each parameter combination was executed on 3 pre-generated graphs
      per regime. The graphs generated with the naive combinatorial edge
      selection scheme only covered graphs with $n \leq 2^{17}$ because of
      the immense time required for generation. However, this should still
      provide enough data points to observe a general trend and make cogent
      comparisons with the much faster but slightly incorrect binomial edge
      selection scheme.
    }
    \paragraph{}{
      Several executables contributed to the testing process:
    }
    \paragraph{\texttt{txt2mpig}}{
      A utility program for converting SNAP edge-centric model text files
      into a compact edge-centric binary format suitable for accessing via MP/IO.
    }
    \paragraph{\texttt{genmpig}}{
      A utility program for generating Erdos-Renyi random graphs and saving
      in a compact edge-centric binary format.
    }
    \paragraph{\texttt{bfs-coco}}{
      A program which reads a compact edge-centric binary format file and
      distributes the vertex-centric equivalent across a $k$-machine context
      and subsequently executes Algorithm~\ref{alg:bfs-coco} on the distributed graph.
    }
    \paragraph{}{
      The reader is directed to the accompanying \texttt{README.md} for
      explicit usage instructions on the various programs as well as
      for a deeper explanation of implementation considerations,
      engineering tradeoffs, and known issues with the programs.
    }
    \paragraph{}{
      It should be noted that the MPI 2.1 standard\autocite{MPI21} and g++-7.2
      was used for development since they were available through the development
      laptop's package system, but the program compiled and ran on the \texttt{crill}
      cluster with g++-5.3.0 and MPI 3.0. The code requires the C++-11 standard.
    }
    \paragraph{}{
      In order to facilitate rapid development, extensive use was made of the C++ STL
      libraries. The vertex input map was a \texttt{std::map}\autocite{map}
      of vertex structures keyed by vertex ID. In each vertex structure, the collections
      of neighbors and BFS tree children were of type \texttt{std::unordered\_set<uint32\_t>}\autocite{unorderedset}.
      The incoming edge map used to facilitate faster lookup on incoming messages was
      accomplished with a \texttt{std::map<std::unordered\_set<uint32\_t>>}. The vertex output
      map was a \texttt<std::vector>\autocite{vector} of vertex structures, but could just
      as easily have been a \texttt{std::map} (and was in earlier development).
    }
    \paragraph{}{
      Randomized elements\autocite{random} made use of the Mersenne twister PRNG \texttt{std::mt19937}\autocite{mt19337}
      as the basis for all probabilistic distributions. The primary distributions used were
      the \texttt{std::uniform\_int\_distribution}\autocite{uniformintdist},
      \texttt{std::bernoulli\_distribution}\autocite{bernoullidist}, and
      \texttt{std::binomial\_distribution}\autocite{binomialdist}.
    }
  }

  \subsection{Erdos-Renyi Graphs}{
    \paragraph{}{
      Results for experiments on the Erdos-Renyi graphs generated by \texttt{genmpig}
      are given in the following figures. The graphs are divided into group plots characterized
      by edge probability, i.e., $p \in [\frac{1-\epsilon}{n}, \frac{1+\epsilon}{n}]$ or
      $p \in [\frac{(1-\epsilon)\ln n}{n}, \frac{(1+\epsilon)\ln n}{n}]$, and by
      edge selection scheme, i.e., Monte Carlo (MCER) or Las Vegas (LVER) Erdos-Renyi graphs.
    }
    %% Monte Carlo
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in
              },
              height=1.5in,
              width=1.5in,
              xlabel=$n$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % 1-
            \linregplots{\footnotesize Load Time}{./er-results/bfs-coco}{.mc.1-}{n}{Tp}
            \linregplots{\footnotesize BFS Time}{./er-results/bfs-coco}{.mc.1-}{n}{Tc}
            \linregplots{\footnotesize Messages}{./er-results/bfs-coco}{.mc.1-}{n}{M}
            \linregplots{\footnotesize Rounds}{./er-results/bfs-coco}{.mc.1-}{n}{r}
            % 1
            \linregplots{}{./er-results/bfs-coco}{.mc.1}{n}{Tp}
            \linregplots{}{./er-results/bfs-coco}{.mc.1}{n}{Tc}
            \linregplots{}{./er-results/bfs-coco}{.mc.1}{n}{M}
            \linregplots{}{./er-results/bfs-coco}{.mc.1}{n}{r}
            % 1+
            \linregplots{}{./er-results/bfs-coco}{.mc.1+}{n}{Tp}
            \linregplots{}{./er-results/bfs-coco}{.mc.1+}{n}{Tc}
            \linregplots{}{./er-results/bfs-coco}{.mc.1+}{n}{M}
            \linregplots{}{./er-results/bfs-coco}{.mc.1+}{n}{r}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{1-\epsilon}{n}$}};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{1}{n}$}};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{1+\epsilon}{n}$}};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexity of Algorithm~\ref{alg:bfs-coco} on MCER Graphs, $p \in [\frac{1-\epsilon}{n}, \frac{1+\epsilon}{n}]$}
        \label{fig:bfs-coco-cplx-mc-er1}
      \end{figure}
    }
    \paragraph{}{
      The graph loading and construction times follow the expected decrease as $k$ scales out, but the BFS search times actually increase
      quite drastically in proportion to $k$. Since the graphs in Figure~\ref{fig:bfs-coco-cplx-mc-er1} are largely disconnected, it may
      be that the message overhead of voting on singleton roots may dominate the search time. Moreover, the single round of no-op gather
      operations per singleton node probably induces overhead, as well.
    }
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in
              },
              height=1.5in,
              width=1.5in,
              xlabel=$n$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % L-
            \linregplots{\footnotesize Load Time}{./er-results/bfs-coco}{.mc.L-}{n}{Tp}
            \linregplots{\footnotesize BFS Time}{./er-results/bfs-coco}{.mc.L-}{n}{Tc}
            \linregplots{\footnotesize Messages}{./er-results/bfs-coco}{.mc.L-}{n}{M}
            \linregplots{\footnotesize Rounds}{./er-results/bfs-coco}{.mc.L-}{n}{r}
            % L
            \linregplots{}{./er-results/bfs-coco}{.mc.L}{n}{Tp}
            \linregplots{}{./er-results/bfs-coco}{.mc.L}{n}{Tc}
            \linregplots{}{./er-results/bfs-coco}{.mc.L}{n}{M}
            \linregplots{}{./er-results/bfs-coco}{.mc.L}{n}{r}
            % L+
            \linregplots{}{./er-results/bfs-coco}{.mc.L+}{n}{Tp}
            \linregplots{}{./er-results/bfs-coco}{.mc.L+}{n}{Tc}
            \linregplots{}{./er-results/bfs-coco}{.mc.L+}{n}{M}
            \linregplots{}{./er-results/bfs-coco}{.mc.L+}{n}{r}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{(1-\epsilon)\ln n}{n}$}};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{\ln n}{n}$}};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{(1+\epsilon)\ln n}{n}$}};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexity of Algorithm~\ref{alg:bfs-coco} on MCER Graphs, $p \in [\frac{(1-\epsilon)\ln n}{n}, \frac{(1+\epsilon)\ln n}{n}]$}
        \label{fig:bfs-coco-cplx-mc-erL}
      \end{figure}
    }
    \paragraph{}{
      The BFS times and load times are more in line with expectations in the regimes depicted by Figure~\ref{fig:bfs-coco-cplx-mc-erL}.
      The total message complexity is two orders of magnitude lower than the experiments depicted by Figure~\ref{fig:bfs-coco-cplx-mc-er1}.
      This further confirms the suspicion that the handling of singleton components is suboptimal under the current implementation.
      The round counts (i.e., counts of paired broadcast and upcast phases) are also significantly smaller, which stands to reason
      since more ``rounds'' would generate more messages.
    }
    %% Las Vegas
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in
              },
              height=1.5in,
              width=1.5in,
              xlabel=$n$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % 1-
            \linregplots{\footnotesize Load Time}{./er-results/bfs-coco}{.vg.1-}{n}{Tp}
            \linregplots{\footnotesize BFS Time}{./er-results/bfs-coco}{.vg.1-}{n}{Tc}
            \linregplots{\footnotesize Messages}{./er-results/bfs-coco}{.vg.1-}{n}{M}
            \linregplots{\footnotesize Rounds}{./er-results/bfs-coco}{.vg.1-}{n}{r}
            % 1
            \linregplots{}{./er-results/bfs-coco}{.vg.1}{n}{Tp}
            \linregplots{}{./er-results/bfs-coco}{.vg.1}{n}{Tc}
            \linregplots{}{./er-results/bfs-coco}{.vg.1}{n}{M}
            \linregplots{}{./er-results/bfs-coco}{.vg.1}{n}{r}
            % 1+
            \linregplots{}{./er-results/bfs-coco}{.vg.1+}{n}{Tp}
            \linregplots{}{./er-results/bfs-coco}{.vg.1+}{n}{Tc}
            \linregplots{}{./er-results/bfs-coco}{.vg.1+}{n}{M}
            \linregplots{}{./er-results/bfs-coco}{.vg.1+}{n}{r}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{1-\epsilon}{n}$}};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{1}{n}$}};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{1+\epsilon}{n}$}};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexity of Algorithm~\ref{alg:bfs-coco} on LVER Graphs, $p \in [\frac{1-\epsilon}{n}, \frac{1+\epsilon}{n}]$}
        \label{fig:bfs-coco-cplx-vg-er1}
      \end{figure}
    }
    \paragraph{}{
      The LVER graphs depicted in Figure~\ref{fig:bfs-coco-cplx-vg-er1} exhibit similar behavior to that shown by the
      MCER graphs depicted in Figure~\ref{fig:bfs-coco-cplx-mc-er1}. This lends support to the rationale behind the MCER edge
      selection scheme as a foundation for a legitimate optimization in graph generation.
    }
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in
              },
              height=1.5in,
              width=1.5in,
              xlabel=$n$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % L-
            \linregplots{\footnotesize Load Time}{./er-results/bfs-coco}{.vg.L-}{n}{Tp}
            \linregplots{\footnotesize BFS Time}{./er-results/bfs-coco}{.vg.L-}{n}{Tc}
            \linregplots{\footnotesize Messages}{./er-results/bfs-coco}{.vg.L-}{n}{M}
            \linregplots{\footnotesize Rounds}{./er-results/bfs-coco}{.vg.L-}{n}{r}
            % L
            \linregplots{}{./er-results/bfs-coco}{.vg.L}{n}{Tp}
            \linregplots{}{./er-results/bfs-coco}{.vg.L}{n}{Tc}
            \linregplots{}{./er-results/bfs-coco}{.vg.L}{n}{M}
            \linregplots{}{./er-results/bfs-coco}{.vg.L}{n}{r}
            % L+
            \linregplots{}{./er-results/bfs-coco}{.vg.L+}{n}{Tp}
            \linregplots{}{./er-results/bfs-coco}{.vg.L+}{n}{Tc}
            \linregplots{}{./er-results/bfs-coco}{.vg.L+}{n}{M}
            \linregplots{}{./er-results/bfs-coco}{.vg.L+}{n}{r}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){\texttt{$p = \frac{(1-\epsilon)\ln n}{n}$}};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){\texttt{$p = \frac{\ln n}{n}$}};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){\texttt{$p = \frac{(1+\epsilon)\ln n}{n}$}};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexity of Algorithm~\ref{alg:bfs-coco} on LVER Graphs, $p \in [\frac{(1-\epsilon)\ln n}{n}, \frac{(1+\epsilon)\ln n}{n}]$}
        \label{fig:bfs-coco-cplx-vg-erL}
      \end{figure}
    }
    \paragraph{}{
      The LVER graphs depicted in Figure~\ref{fig:bfs-coco-cplx-vg-erL} also follow the MCER graphs depicted in Figure~\ref{fig:bfs-coco-cplx-mc-erL}.
      The discrepancy in wall-clock time between the connected and disconnected regimes is likewise reflected.
    }
  }
  \subsection{Real-World Graphs}{
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{groupplot}[
              group style={
                group size=4 by 3,
                xlabels at=edge bottom,
                ylabels at=edge left,
                vertical sep=0.5in
              },
              height=1.5in,
              width=1.5in,
              xlabel=$k$,
              ylabel=$t$ (ns),
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend style={font=\tiny, legend columns=6},
              legend entries={,$k = 1$,,$k = 2$,,$k = 4$,,$k = 8$,,$k = 16$,,$k = 32$},
              legend to name=nprocs
            ]
            % facebook combined
            \linregplots{\footnotesize Load Time}{./rw-results/bfs-coco}{.facebook_combined}{k}{Tp}
            \linregplots{\footnotesize BFS Time}{./rw-results/bfs-coco}{.facebook_combined}{k}{Tc}
            \linregplots{\footnotesize Messages}{./rw-results/bfs-coco}{.facebook_combined}{k}{M}
            \linregplots{\footnotesize Rounds}{./rw-results/bfs-coco}{.facebook_combined}{k}{r}
            % ca-AstroPh
            \linregplots{}{./rw-results/bfs-coco}{.ca-AstroPh}{k}{Tp}
            \linregplots{}{./rw-results/bfs-coco}{.ca-AstroPh}{k}{Tc}
            \linregplots{}{./rw-results/bfs-coco}{.ca-AstroPh}{k}{M}
            \linregplots{}{./rw-results/bfs-coco}{.ca-AstroPh}{k}{r}
            % roadNet-TX
            \linregplots{}{./rw-results/bfs-coco}{.roadNet-TX}{k}{Tp}
            \linregplots{}{./rw-results/bfs-coco}{.roadNet-TX}{k}{Tc}
            \linregplots{}{./rw-results/bfs-coco}{.roadNet-TX}{k}{M}
            \linregplots{}{./rw-results/bfs-coco}{.roadNet-TX}{k}{r}
          \end{groupplot}
          \node[anchor=south] at ($(group c2r1.north east)!0.5!(group c3r1.north west)$){facebook};
          \node[anchor=south] at ($(group c2r2.north east)!0.5!(group c3r2.north west)$){ca-AstroPh};
          \node[anchor=south] at ($(group c2r3.north east)!0.5!(group c3r3.north west)$){roadNet-TX};
          \node[below] at (current bounding box.south){\pgfplotslegendfromname{nprocs}};
        \end{tikzpicture}
        \caption{\footnotesize Empirical Complexity of Algorithm~\ref{alg:bfs-coco} on Real-World Graphs}
        \label{fig:bfs-coco-cplx-rw}
      \end{figure}
    }
    \paragraph{}{
      The real world graphs depicted in Figure~\ref{fig:bfs-coco-cplx-rw} show the expected decrease
      in both BFS and load time for smaller values of $k$, but there appears to be an inflection point
      either at $k = 8$ (\texttt{ca-AstroPh}, \texttt{roadNet-Tx}) or $k = 16$ (\texttt{facebook}).
      The increase in execution time is particularly notable in the ca-AstroPh graph. This probably
      owes to the nature of the division of processes within the cluster for the experiments.
      \begin{longtable}{c|c|c}
        \textbf{$k$} & \textbf{Machines} & \textbf{Cores} \\
        1 & 1 & 1 \\
        2 & 1 & 2 \\
        4 & 2 & 2 \\
        8 & 2 & 4 \\
        16 & 2 & 8 \\
        32 & 4 & 8
      \end{longtable}
      At the higher values of $k$, there was likely more contention for resources within the given
      machine since more processors were occupied per machine.
    }
    \paragraph{}{
      Because the number of available machines were limited by outages and concurrent jobs from
      other users, the experiments were done with a ceiling of 8 processes per machine.
      It is difficult to say whether the 8 processes were mapped to independent cores or to core
      hyperthreads since no constraints of that granularity were employed in the batch scripts.
      Even if the processes were always mapped to independent cores, the contention for memory
      and higher levels of cache could have created bottlenecks, especially in cases of large $n$.
    }
  }
  \subsection{Component Statistics}{
    \paragraph{}{
      The following figures depict component size statistics for all the different regimes.
      Plots are made on logarithmic axes for clarity.
    }
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{loglogaxis}[
              xlabel=$n$,
              log basis x=2,
              ylabel=$n_c$,
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend pos=outer north east,
              legend style={font=\tiny},
              legend entries={
                $p = \frac{1-\epsilon}{n}$ (MC),
                $p = \frac{1}{n}$ (MC),
                $p = \frac{1+\epsilon}{n}$ (MC),
                $p = \frac{(1-\epsilon)\ln n}{n}$ (MC),
                $p = \frac{\ln n}{n}$ (MC),
                $p = \frac{(1+\epsilon)\ln n}{n}$ (MC),
                $p = \frac{1-\epsilon}{n}$ (LV),
                $p = \frac{1}{n}$ (LV),
                $p = \frac{1+\epsilon}{n}$ (LV),
                $p = \frac{(1-\epsilon)\ln n}{n}$ (LV),
                $p = \frac{\ln n}{n}$ (LV),
                $p = \frac{(1+\epsilon)\ln n}{n}$ (LV),
                facebook,
                ca-AstroPh,
                roadNet-TX
              }
            ]
            % 1-
            \addplot [green, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.mc.1-.csv};
            % 1
            \addplot [green, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.mc.1.csv};
            % 1+
            \addplot [green, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.mc.1+.csv};
            % L-
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.mc.L-.csv};
            % L
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.mc.L.csv};
            % L+
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.mc.L+.csv};
            % 1-
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.vg.1-.csv};
            % 1
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.vg.1.csv};
            % 1+
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.vg.1+.csv};
            % L-
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.vg.L-.csv};
            % L
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.vg.L.csv};
            % L+
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=cm] {./er-results/bfs-coco.compstats.vg.L+.csv};
            % facebook combined
            \addplot [black, only marks, mark size=0.5] table [x=n, y=cm] {./rw-results/bfs-coco.compstats.facebook_combined.csv};
            % ca-AstroPh
            \addplot [blue, only marks, mark size=0.5] table [x=n, y=cm] {./rw-results/bfs-coco.compstats.ca-AstroPh.csv};
            % roadNet-TX
            \addplot [red, only marks, mark size=0.5] table [x=n, y=cm] {./rw-results/bfs-coco.compstats.roadNet-TX.csv};
          \end{loglogaxis}
        \end{tikzpicture}
        \caption{\footnotesize Component Mean Size for Various Regimes}
        \label{fig:bfs-coco-compmean}
      \end{figure}
    }
    \paragraph{}{
      In Figure~\ref{fig:bfs-coco-compmean}, the component mean size climbs with total vertex population size in the case where
      $p$ is close to $\frac{\ln n}{n}$. This suggests a significantly higher degree of connectivity than the case where $p$ is
      close to $\frac{1}{n}$, where the components appear to be singletons or very nearly singletons on average. It would seem
      that setting $\epsilon = 0.2$  may be too tight to observe the transition threshold alluded to in the assignment specification\autocite[5]{pa2spec}.
      Widening $\epsilon$ to $0.5$ or greater may have offered a more stark comparison. It is interesting to note that the component
      size for \texttt{facebook} suggests complete connection whereas that for \texttt{ca-AstroPh} and \texttt{roadNet-TX} exhibit
      slightly lower connectivity, though not as low as the Erdos-Renyi graphs where $p$ is close to $\frac{1}{n}$.
    }
    \paragraph{}{
      \begin{figure}
        \begin{tikzpicture}
          \footnotesize
          \begin{loglogaxis}[
              xlabel=$n$,
              log basis x=2,
              ylabel=$n_c$,
              tick label style={font=\tiny},
              label style={font=\tiny},
              legend pos=outer north east,
              legend style={font=\tiny},
              legend entries={
                $p = \frac{1-\epsilon}{n}$ (MC),
                $p = \frac{1}{n}$ (MC),
                $p = \frac{1+\epsilon}{n}$ (MC),
                $p = \frac{(1-\epsilon)\ln n}{n}$ (MC),
                $p = \frac{\ln n}{n}$ (MC),
                $p = \frac{(1+\epsilon)\ln n}{n}$ (MC),
                $p = \frac{1-\epsilon}{n}$ (LV),
                $p = \frac{1}{n}$ (LV),
                $p = \frac{1+\epsilon}{n}$ (LV),
                $p = \frac{(1-\epsilon)\ln n}{n}$ (LV),
                $p = \frac{\ln n}{n}$ (LV),
                $p = \frac{(1+\epsilon)\ln n}{n}$ (LV),
                facebook,
                ca-AstroPh,
                roadNet-TX
              }
            ]
            % 1-
            \addplot [green, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.mc.1-.csv};
            % 1
            \addplot [green, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.mc.1.csv};
            % 1+
            \addplot [green, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.mc.1+.csv};
            % L-
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.mc.L-.csv};
            % L
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.mc.L.csv};
            % L+
            \addplot [orange, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.mc.L+.csv};
            % 1-
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.vg.1-.csv};
            % 1
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.vg.1.csv};
            % 1+
            \addplot [magenta, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.vg.1+.csv};
            % L-
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.vg.L-.csv};
            % L
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.vg.L.csv};
            % L+
            \addplot [cyan, only marks, mark size=0.5] table [x=n, y=f] {./er-results/bfs-coco.compstats.vg.L+.csv};
            % facebook combined
            \addplot [black, only marks, mark size=0.5] table [x=n, y=f] {./rw-results/bfs-coco.compstats.facebook_combined.csv};
            % ca-AstroPh
            \addplot [blue, only marks, mark size=0.5] table [x=n, y=f] {./rw-results/bfs-coco.compstats.ca-AstroPh.csv};
            % roadNet-TX
            \addplot [red, only marks, mark size=0.5] table [x=n, y=f] {./rw-results/bfs-coco.compstats.roadNet-TX.csv};
          \end{loglogaxis}
        \end{tikzpicture}
        \caption{\footnotesize Component Counts for Various Regimes}
        \label{fig:bfs-coco-forest}
      \end{figure}
    }
    \paragraph{}{
      Figure~\ref{fig:bfs-coco-forest} confirms the suggestions arising from Figure~\ref{fig:bfs-coco-compmean}
      in a more concrete fashion. The Facebook graph is completely connected. The network of
      co-publishing astrophysicists seems to have between 100 and 1000 clusters of scientists.
      This probably could be considered as a marker for institution or subfield, though without
      more explicit data it is impossible to say for certain. The Texas road network graph is
      a little more surprising since one might have expected something closer to complete connectivity.
      The components could be a marker for the urban/rural divide since all the major cities in
      Texas would have been connected by major freeways. The isolates would likely be smaller towns
      or possibly farmland and ranches with relatively self-contained road subnets.
    }
  }
}

\section{Conclusions}{
  \paragraph{}{
    Some optimizations around the handling of singleton components are sorely wanted here.
    One optimization would be to preprocess singletons locally in a single pass over a local
    population and perform an all-gather operation to ensure that the forest was up to date
    among all participating machines. There would be no need for broadcast or upcast phases,
    which would avoid superfluous messages in terms of voting, exchange, and termination checking.
  }
  \paragraph{}{
    The Monte Carlo edge selection scheme appears to have enjoyed mild success as a simulacrum
    for the exceedingly more time-consuming Las Vegas edge selection scheme. With some minor
    tweaks, the former coould be improved to more correctly simulate the intensive Bernoulli
    trials of the latter.
  }
  \paragraph{}{
    The primary deficiency of the implementation is in its poor performance for high values of $k$.
    Some careful thought will need to be given to overcome these issues. While using utilities
    like \texttt{callgrind} uncovered major inefficiencies in the implementation, it was difficult
    to test longer runs because of the inherent overhead that profiling utilities would add to an
    already long execution time. A focus on moving as much computation as possible into the local
    sphere would likely yield the best dividends.
  }
}

\printbibliography
\end{document}
